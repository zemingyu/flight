{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Resources list**\n",
    "1. pyspark tutorial https://github.com/pydatasg/Pydata_meetup_Nov_16/blob/master/RF_modeling_2.3_business_weimin.ipynb\n",
    "2. follow this tutorial: https://www.analyticsvidhya.com/blog/2016/10/spark-dataframe-and-operations/\n",
    "3. and this one: https://www.dezyre.com/apache-spark-tutorial/pyspark-tutorial\n",
    "4. data engineer trick: http://nadbordrozd.github.io/blog/2016/05/22/one-weird-trick-that-will-fix-your-pyspark-schemas/\n",
    "5. git http://rogerdudler.github.io/git-guide/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get data\n",
    "## Downloand data from s3\n",
    "version 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "! cd /home/ubuntu/s3/flight_1_5\n",
    "\n",
    "! aws s3 sync s3://flight.price/flight_1_5 . "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "version 1.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "! aws s3 ls s3://flight.price.11/flight_1_5 --recursive\n",
    "! aws s3 sync s3://flight.price.11/flight_1_5 ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "! du -h"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract\n",
    "Note: version 1.1 from 2017-05-11 onwards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import zipfile\n",
    "import os\n",
    "\n",
    "# dir_in = 'C:\\\\s3\\\\20170503\\\\flight_1_6' # sydney to shanghai\n",
    "# dir_in = 'C:\\\\s3\\\\20170503\\\\flight_5_1' # beijing to sydney\n",
    "# dir_in = 'C:\\\\s3\\\\20170503'\n",
    "dir_in = '/home/ubuntu/s3/flight_1_5'\n",
    "\n",
    "# dir_out = 'C:\\\\s3\\\\20170503_extracted\\\\flight_1_6'\n",
    "dir_out = '/home/ubuntu/s3/flight_1_5/extracted'\n",
    "extension = \".zip\"\n",
    "\n",
    "os.chdir(dir_in) # change directory from working dir to dir with files\n",
    "\n",
    "for subdir, dirs, files in os.walk(dir_in):\n",
    "    for item in files:\n",
    "        if item.endswith(extension): # check for \".zip\" extension\n",
    "            file_name = os.path.join(subdir, item)\n",
    "#             file_name = os.path.abspath(item) # get full path of files\n",
    "            zip_ref = zipfile.ZipFile(file_name) # create zipfile object\n",
    "            zip_ref.extractall(dir_out) # extract file to dir\n",
    "            zip_ref.close() # close file  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Move files in final_results to the main folder and delete the folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# ! cd /home/ubuntu/s3/flight_1_5/extracted\n",
    "# ! mv /home/ubuntu/s3/flight_1_5/extracted/final_results/*.txt .\n",
    "! find /home/ubuntu/s3/flight_1_5/extracted/final_results -name '*.txt' -exec mv {} /home/ubuntu/s3/flight_1_5/extracted \\;\n",
    "# -exec runs any command,  {} inserts the filename found, \\; marks the end of the exec command.\n",
    "! rmdir /home/ubuntu/s3/flight_1_5/extracted/final_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "http://stackoverflow.com/questions/9157138/recursively-counting-files-in-a-linux-directory\n",
    "* -type f to include only files.  \n",
    "* | (and not Â¦) redirects find command's standard output to wc command's standard input.  \n",
    "* wc (short for word count) counts newlines, words and bytes on its input (docs).  \n",
    "* -l to count just newlines.\n",
    "* You can also remove the -type f to include directories (and symlinks) in the count.\n",
    "* It's possible this command will overcount if filenames can contain newline characters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "! find /home/ubuntu/s3/flight_1_5/extracted -type f | wc -l\n",
    "! du -sh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Launch spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.1.1'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import h2o\n",
    "# import pysparkling\n",
    "import os\n",
    "import sys\n",
    "from pyspark.sql import SparkSession\n",
    "from IPython.display import display\n",
    "from pyspark.sql.functions import regexp_extract, col, split, udf, trim, when, from_unixtime, unix_timestamp, minute, hour, datediff\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.types import IntegerType, StringType, BooleanType\n",
    "# from pyspark.sql.types import *\n",
    "import datetime\n",
    "import argparse\n",
    "import json\n",
    "import glob, os, shutil\n",
    "\n",
    "from pyspark import SparkContext\n",
    "sc = SparkContext()\n",
    "\n",
    "# # # spark_home = os.environ.get('SPARK_HOME', None)\n",
    "# spark_home = \"C:\\spark-2.1.0-bin-hadoop2.7\\spark-2.1.0-bin-hadoop2.7\"\n",
    "\n",
    "# if not spark_home:\n",
    "\n",
    "#     raise ValueError('SPARK_HOME environment variable is not set')\n",
    "\n",
    "# sys.path.insert(0, os.path.join(spark_home, 'python'))\n",
    "\n",
    "# sys.path.insert(0, os.path.join(spark_home, 'C:\\spark-2.1.0-bin-hadoop2.7\\spark-2.1.0-bin-hadoop2.7\\python\\lib\\py4j-0.10.4-src.zip')) ## may need to adjust on your system depending on which Spark version you're using and where you installed it.\n",
    "\n",
    "# exec(open(os.path.join(spark_home, 'python/pyspark/shell.py')).read())\n",
    "\n",
    "spark = SparkSession \\\n",
    "        .builder \\\n",
    "        .appName(\"Python Spark SQL basic example\") \\\n",
    "        .config(\"spark.some.config.option\", \"some-value\") \\\n",
    "        .getOrCreate()\n",
    "        \n",
    "spark.version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# hc= H2OContext(sc).start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# h2o not working yet\n",
    "# # Start H2O Context\n",
    "# from pysparkling import *\n",
    "# sc\n",
    "# hc= H2OContext(sc).start()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read in json files and aggregate into a dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copy version 1.1 files to a separate folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def mkfldr(fldr):\n",
    "    try:\n",
    "      os.makedirs(fldr)\n",
    "    except:\n",
    "      print(\"Folder already exist or some error\")\n",
    "    \n",
    "def read_from_json_file(filename):\n",
    "    with open(filename,'r') as f:\n",
    "        d = json.load(f)   \n",
    "    return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "src_fldr = \"/home/ubuntu/s3/flight_1_5/extracted\"\n",
    "dst_fldr = \"/home/ubuntu/s3/flight_1_5/extracted11\"\n",
    "\n",
    "mkfldr(dst_fldr)\n",
    "\n",
    "for txt_file in glob.glob(os.path.join(parent_dir, 'flight_1_5_price_2017-05-1[1-4]*.txt')):\n",
    "    shutil.move(txt_file, dst_fldr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Append multiple json files to a single jsonl file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "! find -type f -name \"flight_1_5_price_2017-05-10_2017-06-10*.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "comb_fldr = '/home/ubuntu/s3/comb'\n",
    "mkfldr(comb_fldr)\n",
    "\n",
    "pq_fldr = '/home/ubuntu/s3/pq'\n",
    "mkfldr(pq_fldr)\n",
    "\n",
    "os.chdir('/home/ubuntu/s3/flight_1_5/extracted')\n",
    "\n",
    "# json_file_name = 'flight_1_5_price_2017-05-10_2017-11-06_2_7.txt'\n",
    "# pq_file_name = os.path.join(pq_fldr, json_file_name.replace('.jsonl','.parquet'))\n",
    "\n",
    "json_file_name = 'flight_1_5_price_2017-05-10_2017-06-10*.txt'\n",
    "jsonl_file_name = os.path.join(comb_fldr, json_file_name.replace('.txt','.jsonl'))\n",
    "\n",
    "# 'flight_1_5_price_2017-05-[8|9|10]*.txt'\n",
    "\n",
    "with open(jsonl_file_name, 'w') as outfile:\n",
    "    for file in glob.glob(json_file_name):                \n",
    "        d = read_from_json_file(file)                \n",
    "        json.dump(d, outfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read in jsonl file, flatten it, and save as a new flat jsonl file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set parquet schema and create empty parquet file to append to\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def chunkIt(seq, num):\n",
    "  avg = len(seq) / float(num)\n",
    "  index_start = []\n",
    "  index_end = []\n",
    "  last = 0.0\n",
    "\n",
    "  while last < len(seq):\n",
    "#     out.append(seq[int(last):int(last + avg)])\n",
    "    index_start.append(int(last))\n",
    "    index_end.append(int(last + avg))\n",
    "    last += avg\n",
    "\n",
    "  return list(zip(index_start, index_end))\n",
    "\n",
    "# files = [os.path.join(ext_fldr, \"flight_1_5_price_2017-04-06_2017-04-07_1_0.txt\"), \n",
    "#         os.path.join(ext_fldr, \"flight_1_5_price_2017-04-06_2017-04-07_2_7.txt\")]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set chunk size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22665\n",
      "[(0, 226), (226, 453), (453, 679), (679, 906), (906, 1133), (1133, 1359), (1359, 1586), (1586, 1813), (1813, 2039), (2039, 2266), (2266, 2493), (2493, 2719), (2719, 2946), (2946, 3173), (3173, 3399), (3399, 3626), (3626, 3853), (3853, 4079), (4079, 4306), (4306, 4533), (4533, 4759), (4759, 4986), (4986, 5212), (5212, 5439), (5439, 5666), (5666, 5892), (5892, 6119), (6119, 6346), (6346, 6572), (6572, 6799), (6799, 7026), (7026, 7252), (7252, 7479), (7479, 7706), (7706, 7932), (7932, 8159), (8159, 8386), (8386, 8612), (8612, 8839), (8839, 9065), (9065, 9292), (9292, 9519), (9519, 9745), (9745, 9972), (9972, 10199), (10199, 10425), (10425, 10652), (10652, 10879), (10879, 11105), (11105, 11332), (11332, 11559), (11559, 11785), (11785, 12012), (12012, 12239), (12239, 12465), (12465, 12692), (12692, 12919), (12919, 13145), (13145, 13372), (13372, 13598), (13598, 13825), (13825, 14052), (14052, 14278), (14278, 14505), (14505, 14732), (14732, 14958), (14958, 15185), (15185, 15412), (15412, 15638), (15638, 15865), (15865, 16092), (16092, 16318), (16318, 16545), (16545, 16772), (16772, 16998), (16998, 17225), (17225, 17452), (17452, 17678), (17678, 17905), (17905, 18131), (18131, 18358), (18358, 18585), (18585, 18811), (18811, 19038), (19038, 19265), (19265, 19491), (19491, 19718), (19718, 19945), (19945, 20171), (20171, 20398), (20398, 20625), (20625, 20851), (20851, 21078), (21078, 21305), (21305, 21531), (21531, 21758), (21758, 21985), (21985, 22211), (22211, 22438), (22438, 22665)]\n",
      "226\n"
     ]
    }
   ],
   "source": [
    "ext_fldr = '/home/ubuntu/s3/flight_1_5/extracted'\n",
    "file_count = len(glob.glob(os.path.join(ext_fldr, \"*.txt\")))\n",
    "range_temp = chunkIt(range(file_count), 100)\n",
    "\n",
    "print(file_count)\n",
    "print(range_temp)\n",
    "print(range_temp[0][1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create empty parquet file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/s3/flight_1_5/extracted/flight_1_5_price_2017-04-23_2017-04-30_2_21.txt completed. Count: 1\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import os\n",
    "from pandas.io.json import json_normalize\n",
    "\n",
    "pd.options.display.max_columns = 99\n",
    "\n",
    "flat_table_list = []  # a list\n",
    "\n",
    "ext_fldr = '/home/ubuntu/s3/flight_1_5/extracted'\n",
    "comb_fldr = '/home/ubuntu/s3/comb'\n",
    "# os.chdir(comb_fldr)\n",
    "# file_list = os.listdir(comb_fldr)\n",
    "\n",
    "aggDF = pd.DataFrame() #aggregate dataframe to hold all individual dataframes\n",
    "count = 0\n",
    "\n",
    "for file in glob.glob(os.path.join(ext_fldr, \"*.txt\"))[0:1]:\n",
    "    with open(file) as f:               \n",
    "        flat_table = []  # a list\n",
    "        d = json.load(f)\n",
    "        flight_list = json_normalize(d['flight_list'])\n",
    "        basic = json_normalize(d['basic'])\n",
    "        \n",
    "        # create dataframe\n",
    "        basic = basic.drop('search_date', 1)\n",
    "        basic['tmp'] = 1\n",
    "        flight_list = flight_list.drop('id', 1)\n",
    "        flight_list['tmp'] = 1\n",
    "        DF = pd.merge(basic, flight_list, on=['tmp'])\n",
    "        DF=DF.drop('tmp', 1)\n",
    "        \n",
    "        # append\n",
    "        aggDF = aggDF.append(DF)\n",
    "        \n",
    "        count = count + 1\n",
    "        \n",
    "        print(file+\" completed. Count: \" + str(count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(114, 29)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aggDF.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['from_city_name', 'start_date', 'stay_days', 'table_name', 'task_id',\n",
       "       'to_city_name', 'trip', 'version', 'airline_code', 'airline_codes',\n",
       "       'arr_time', 'check_bag_inc', 'company', 'dep_time', 'duration',\n",
       "       'flight_code', 'flight_number', 'index', 'plane', 'power', 'price',\n",
       "       'price_code', 'search_date', 'span_days', 'stop', 'stop_info',\n",
       "       'ticket_left', 'video', 'wifi'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aggDF.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>from_city_name</th>\n",
       "      <th>start_date</th>\n",
       "      <th>stay_days</th>\n",
       "      <th>table_name</th>\n",
       "      <th>task_id</th>\n",
       "      <th>to_city_name</th>\n",
       "      <th>trip</th>\n",
       "      <th>version</th>\n",
       "      <th>airline_code</th>\n",
       "      <th>airline_codes</th>\n",
       "      <th>arr_time</th>\n",
       "      <th>check_bag_inc</th>\n",
       "      <th>company</th>\n",
       "      <th>dep_time</th>\n",
       "      <th>duration</th>\n",
       "      <th>flight_code</th>\n",
       "      <th>flight_number</th>\n",
       "      <th>index</th>\n",
       "      <th>plane</th>\n",
       "      <th>power</th>\n",
       "      <th>price</th>\n",
       "      <th>price_code</th>\n",
       "      <th>search_date</th>\n",
       "      <th>span_days</th>\n",
       "      <th>stop</th>\n",
       "      <th>stop_info</th>\n",
       "      <th>ticket_left</th>\n",
       "      <th>video</th>\n",
       "      <th>wifi</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sydney</td>\n",
       "      <td>2017-04-30</td>\n",
       "      <td>21</td>\n",
       "      <td>flight_1_5_price</td>\n",
       "      <td>34</td>\n",
       "      <td>beijing</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>CX</td>\n",
       "      <td>[CX, KA]</td>\n",
       "      <td>2017-04-30T22:30:00.000+08:00</td>\n",
       "      <td>False</td>\n",
       "      <td>Cathay Pacific</td>\n",
       "      <td>2017-04-30T10:05:00.000+10:00</td>\n",
       "      <td>14h25m</td>\n",
       "      <td>CX162</td>\n",
       "      <td>162</td>\n",
       "      <td>50</td>\n",
       "      <td>AIRBUS INDUSTRIE A330-300</td>\n",
       "      <td>True</td>\n",
       "      <td>1001.79</td>\n",
       "      <td>AUD</td>\n",
       "      <td>2017-04-23</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Hong Kong(HKG):1h10m</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sydney</td>\n",
       "      <td>2017-04-30</td>\n",
       "      <td>21</td>\n",
       "      <td>flight_1_5_price</td>\n",
       "      <td>34</td>\n",
       "      <td>beijing</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>CX</td>\n",
       "      <td>[CX, KA]</td>\n",
       "      <td>2017-04-30T23:25:00.000+08:00</td>\n",
       "      <td>False</td>\n",
       "      <td>Cathay Pacific</td>\n",
       "      <td>2017-04-30T10:05:00.000+10:00</td>\n",
       "      <td>15h20m</td>\n",
       "      <td>CX162</td>\n",
       "      <td>162</td>\n",
       "      <td>77</td>\n",
       "      <td>AIRBUS INDUSTRIE A330-300</td>\n",
       "      <td>False</td>\n",
       "      <td>1001.79</td>\n",
       "      <td>AUD</td>\n",
       "      <td>2017-04-23</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Hong Kong(HKG):2h10m</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sydney</td>\n",
       "      <td>2017-04-30</td>\n",
       "      <td>21</td>\n",
       "      <td>flight_1_5_price</td>\n",
       "      <td>34</td>\n",
       "      <td>beijing</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>CX</td>\n",
       "      <td>[CX, CX]</td>\n",
       "      <td>2017-05-22T08:45:00.000+10:00</td>\n",
       "      <td>False</td>\n",
       "      <td>Cathay Pacific</td>\n",
       "      <td>2017-05-21T15:30:00.000+08:00</td>\n",
       "      <td>15h15m</td>\n",
       "      <td>CX6115</td>\n",
       "      <td>6115</td>\n",
       "      <td>47</td>\n",
       "      <td>Airbus A321</td>\n",
       "      <td>False</td>\n",
       "      <td>952.04</td>\n",
       "      <td>AUD</td>\n",
       "      <td>2017-04-23</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Hong Kong(HKG):2h30m</td>\n",
       "      <td>4</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sydney</td>\n",
       "      <td>2017-04-30</td>\n",
       "      <td>21</td>\n",
       "      <td>flight_1_5_price</td>\n",
       "      <td>34</td>\n",
       "      <td>beijing</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>CZ</td>\n",
       "      <td>[CZ, CZ]</td>\n",
       "      <td>2017-05-22T08:25:00.000+10:00</td>\n",
       "      <td>False</td>\n",
       "      <td>China Southern Airlines</td>\n",
       "      <td>2017-05-21T14:30:00.000+08:00</td>\n",
       "      <td>15h55m</td>\n",
       "      <td>CZ3162</td>\n",
       "      <td>3162</td>\n",
       "      <td>29</td>\n",
       "      <td>Airbus A330</td>\n",
       "      <td>False</td>\n",
       "      <td>891.44</td>\n",
       "      <td>AUD</td>\n",
       "      <td>2017-04-23</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Guangzhou(CAN):3h10m</td>\n",
       "      <td>6</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sydney</td>\n",
       "      <td>2017-04-30</td>\n",
       "      <td>21</td>\n",
       "      <td>flight_1_5_price</td>\n",
       "      <td>34</td>\n",
       "      <td>beijing</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>CX</td>\n",
       "      <td>[CX, CX]</td>\n",
       "      <td>2017-04-30T19:20:00.000+08:00</td>\n",
       "      <td>False</td>\n",
       "      <td>Cathay Pacific</td>\n",
       "      <td>2017-04-30T07:30:00.000+10:00</td>\n",
       "      <td>13h50m</td>\n",
       "      <td>CX110</td>\n",
       "      <td>110</td>\n",
       "      <td>14</td>\n",
       "      <td>AIRBUS INDUSTRIE A330-300</td>\n",
       "      <td>True</td>\n",
       "      <td>952.04</td>\n",
       "      <td>AUD</td>\n",
       "      <td>2017-04-23</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Hong Kong(HKG):0h50m</td>\n",
       "      <td>9</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>sydney</td>\n",
       "      <td>2017-04-30</td>\n",
       "      <td>21</td>\n",
       "      <td>flight_1_5_price</td>\n",
       "      <td>34</td>\n",
       "      <td>beijing</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NZ</td>\n",
       "      <td>[NZ]</td>\n",
       "      <td>2017-05-01T05:30:00.000+08:00</td>\n",
       "      <td>False</td>\n",
       "      <td>Air New Zealand</td>\n",
       "      <td>2017-04-30T19:40:00.000+10:00</td>\n",
       "      <td>11h50m</td>\n",
       "      <td>NZ3884</td>\n",
       "      <td>3884</td>\n",
       "      <td>36</td>\n",
       "      <td>AIRBUS INDUSTRIE A330-300</td>\n",
       "      <td>False</td>\n",
       "      <td>2314.16</td>\n",
       "      <td>AUD</td>\n",
       "      <td>2017-04-23</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>7</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>sydney</td>\n",
       "      <td>2017-04-30</td>\n",
       "      <td>21</td>\n",
       "      <td>flight_1_5_price</td>\n",
       "      <td>34</td>\n",
       "      <td>beijing</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>VN</td>\n",
       "      <td>[VN, VN]</td>\n",
       "      <td>2017-05-22T12:15:00.000+10:00</td>\n",
       "      <td>False</td>\n",
       "      <td>Vietnam Airlines</td>\n",
       "      <td>2017-05-21T15:45:00.000+08:00</td>\n",
       "      <td>18h30m</td>\n",
       "      <td>VN513</td>\n",
       "      <td>513</td>\n",
       "      <td>15</td>\n",
       "      <td>Boeing 787</td>\n",
       "      <td>False</td>\n",
       "      <td>1578.64</td>\n",
       "      <td>AUD</td>\n",
       "      <td>2017-04-23</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Hanoi(HAN):5h30m</td>\n",
       "      <td>4</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>sydney</td>\n",
       "      <td>2017-04-30</td>\n",
       "      <td>21</td>\n",
       "      <td>flight_1_5_price</td>\n",
       "      <td>34</td>\n",
       "      <td>beijing</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>CX</td>\n",
       "      <td>[CX, KA]</td>\n",
       "      <td>2017-05-01T11:40:00.000+08:00</td>\n",
       "      <td>False</td>\n",
       "      <td>Cathay Pacific</td>\n",
       "      <td>2017-04-30T21:55:00.000+10:00</td>\n",
       "      <td>15h45m</td>\n",
       "      <td>CX138</td>\n",
       "      <td>138</td>\n",
       "      <td>63</td>\n",
       "      <td>BOEING 777-300ER</td>\n",
       "      <td>False</td>\n",
       "      <td>1001.79</td>\n",
       "      <td>AUD</td>\n",
       "      <td>2017-04-23</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Hong Kong(HKG):3h15m</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>sydney</td>\n",
       "      <td>2017-04-30</td>\n",
       "      <td>21</td>\n",
       "      <td>flight_1_5_price</td>\n",
       "      <td>34</td>\n",
       "      <td>beijing</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>FJ</td>\n",
       "      <td>[FJ, SQ]</td>\n",
       "      <td>2017-05-01T07:15:00.000+08:00</td>\n",
       "      <td>False</td>\n",
       "      <td>Fiji Airways</td>\n",
       "      <td>2017-04-30T15:50:00.000+10:00</td>\n",
       "      <td>17h25m</td>\n",
       "      <td>FJ5320</td>\n",
       "      <td>5320</td>\n",
       "      <td>49</td>\n",
       "      <td>AIRBUS INDUSTRIE A330-200</td>\n",
       "      <td>False</td>\n",
       "      <td>5552.39</td>\n",
       "      <td>AUD</td>\n",
       "      <td>2017-04-23</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Singapore(SIN):2h55m</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>sydney</td>\n",
       "      <td>2017-04-30</td>\n",
       "      <td>21</td>\n",
       "      <td>flight_1_5_price</td>\n",
       "      <td>34</td>\n",
       "      <td>beijing</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>CX</td>\n",
       "      <td>[CX, CX]</td>\n",
       "      <td>2017-05-22T08:45:00.000+10:00</td>\n",
       "      <td>False</td>\n",
       "      <td>Cathay Pacific</td>\n",
       "      <td>2017-05-21T16:35:00.000+08:00</td>\n",
       "      <td>14h10m</td>\n",
       "      <td>CX331</td>\n",
       "      <td>331</td>\n",
       "      <td>38</td>\n",
       "      <td>AIRBUS INDUSTRIE A330-300</td>\n",
       "      <td>True</td>\n",
       "      <td>952.04</td>\n",
       "      <td>AUD</td>\n",
       "      <td>2017-04-23</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Hong Kong(HKG):1h5m</td>\n",
       "      <td>9</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>sydney</td>\n",
       "      <td>2017-04-30</td>\n",
       "      <td>21</td>\n",
       "      <td>flight_1_5_price</td>\n",
       "      <td>34</td>\n",
       "      <td>beijing</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>CZ</td>\n",
       "      <td>[CZ, CZ]</td>\n",
       "      <td>2017-05-01T15:15:00.000+08:00</td>\n",
       "      <td>False</td>\n",
       "      <td>China Southern Airlines</td>\n",
       "      <td>2017-04-30T21:45:00.000+10:00</td>\n",
       "      <td>19h30m</td>\n",
       "      <td>CZ302</td>\n",
       "      <td>302</td>\n",
       "      <td>51</td>\n",
       "      <td>Airbus A330</td>\n",
       "      <td>False</td>\n",
       "      <td>1332.69</td>\n",
       "      <td>AUD</td>\n",
       "      <td>2017-04-23</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Guangzhou(CAN):6h35m</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>sydney</td>\n",
       "      <td>2017-04-30</td>\n",
       "      <td>21</td>\n",
       "      <td>flight_1_5_price</td>\n",
       "      <td>34</td>\n",
       "      <td>beijing</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>CZ</td>\n",
       "      <td>[CZ, CZ]</td>\n",
       "      <td>2017-05-01T12:15:00.000+08:00</td>\n",
       "      <td>False</td>\n",
       "      <td>China Southern Airlines</td>\n",
       "      <td>2017-04-30T21:45:00.000+10:00</td>\n",
       "      <td>16h30m</td>\n",
       "      <td>CZ302</td>\n",
       "      <td>302</td>\n",
       "      <td>13</td>\n",
       "      <td>Airbus A330</td>\n",
       "      <td>False</td>\n",
       "      <td>891.44</td>\n",
       "      <td>AUD</td>\n",
       "      <td>2017-04-23</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Guangzhou(CAN):3h35m</td>\n",
       "      <td>6</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>sydney</td>\n",
       "      <td>2017-04-30</td>\n",
       "      <td>21</td>\n",
       "      <td>flight_1_5_price</td>\n",
       "      <td>34</td>\n",
       "      <td>beijing</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>QF</td>\n",
       "      <td>[QF]</td>\n",
       "      <td>2017-05-22T13:20:00.000+10:00</td>\n",
       "      <td>False</td>\n",
       "      <td>Qantas Airways</td>\n",
       "      <td>2017-05-21T23:45:00.000+08:00</td>\n",
       "      <td>11h35m</td>\n",
       "      <td>QF108</td>\n",
       "      <td>108</td>\n",
       "      <td>5</td>\n",
       "      <td>AIRBUS INDUSTRIE A330-200</td>\n",
       "      <td>False</td>\n",
       "      <td>800.24</td>\n",
       "      <td>AUD</td>\n",
       "      <td>2017-04-23</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>9</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>sydney</td>\n",
       "      <td>2017-04-30</td>\n",
       "      <td>21</td>\n",
       "      <td>flight_1_5_price</td>\n",
       "      <td>34</td>\n",
       "      <td>beijing</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>CZ</td>\n",
       "      <td>[CZ, CZ]</td>\n",
       "      <td>2017-05-01T11:10:00.000+08:00</td>\n",
       "      <td>False</td>\n",
       "      <td>China Southern Airlines</td>\n",
       "      <td>2017-04-30T21:45:00.000+10:00</td>\n",
       "      <td>15h25m</td>\n",
       "      <td>CZ302</td>\n",
       "      <td>302</td>\n",
       "      <td>11</td>\n",
       "      <td>Airbus A330</td>\n",
       "      <td>False</td>\n",
       "      <td>891.44</td>\n",
       "      <td>AUD</td>\n",
       "      <td>2017-04-23</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Guangzhou(CAN):2h35m</td>\n",
       "      <td>6</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>sydney</td>\n",
       "      <td>2017-04-30</td>\n",
       "      <td>21</td>\n",
       "      <td>flight_1_5_price</td>\n",
       "      <td>34</td>\n",
       "      <td>beijing</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>MU</td>\n",
       "      <td>[MU, MU]</td>\n",
       "      <td>2017-05-22T07:40:00.000+10:00</td>\n",
       "      <td>False</td>\n",
       "      <td>China Eastern Airlines</td>\n",
       "      <td>2017-05-21T11:30:00.000+08:00</td>\n",
       "      <td>18h10m</td>\n",
       "      <td>MU2452</td>\n",
       "      <td>2452</td>\n",
       "      <td>1</td>\n",
       "      <td>BOEING 737-800 (WINGLETS) PASSENGER</td>\n",
       "      <td>False</td>\n",
       "      <td>471.74</td>\n",
       "      <td>AUD</td>\n",
       "      <td>2017-04-23</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Wuhan(WUH):5h20m</td>\n",
       "      <td>9</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>sydney</td>\n",
       "      <td>2017-04-30</td>\n",
       "      <td>21</td>\n",
       "      <td>flight_1_5_price</td>\n",
       "      <td>34</td>\n",
       "      <td>beijing</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>CX</td>\n",
       "      <td>[CX, CX]</td>\n",
       "      <td>2017-05-01T12:20:00.000+08:00</td>\n",
       "      <td>False</td>\n",
       "      <td>Cathay Pacific</td>\n",
       "      <td>2017-04-30T21:55:00.000+10:00</td>\n",
       "      <td>16h25m</td>\n",
       "      <td>CX138</td>\n",
       "      <td>138</td>\n",
       "      <td>19</td>\n",
       "      <td>BOEING 777-300ER</td>\n",
       "      <td>True</td>\n",
       "      <td>952.04</td>\n",
       "      <td>AUD</td>\n",
       "      <td>2017-04-23</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Hong Kong(HKG):3h45m</td>\n",
       "      <td>9</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>sydney</td>\n",
       "      <td>2017-04-30</td>\n",
       "      <td>21</td>\n",
       "      <td>flight_1_5_price</td>\n",
       "      <td>34</td>\n",
       "      <td>beijing</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>CX</td>\n",
       "      <td>[CX, KA]</td>\n",
       "      <td>2017-04-30T22:30:00.000+08:00</td>\n",
       "      <td>False</td>\n",
       "      <td>Cathay Pacific</td>\n",
       "      <td>2017-04-30T07:30:00.000+10:00</td>\n",
       "      <td>17h0m</td>\n",
       "      <td>CX110</td>\n",
       "      <td>110</td>\n",
       "      <td>73</td>\n",
       "      <td>AIRBUS INDUSTRIE A330-300</td>\n",
       "      <td>True</td>\n",
       "      <td>1001.79</td>\n",
       "      <td>AUD</td>\n",
       "      <td>2017-04-23</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Hong Kong(HKG):3h50m</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>sydney</td>\n",
       "      <td>2017-04-30</td>\n",
       "      <td>21</td>\n",
       "      <td>flight_1_5_price</td>\n",
       "      <td>34</td>\n",
       "      <td>beijing</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>MF</td>\n",
       "      <td>[MF, MF]</td>\n",
       "      <td>2017-05-22T09:15:00.000+10:00</td>\n",
       "      <td>False</td>\n",
       "      <td>Xiamen Airlines</td>\n",
       "      <td>2017-05-21T16:20:00.000+08:00</td>\n",
       "      <td>14h55m</td>\n",
       "      <td>MF8108</td>\n",
       "      <td>8108</td>\n",
       "      <td>2</td>\n",
       "      <td>Boeing 787</td>\n",
       "      <td>False</td>\n",
       "      <td>670.74</td>\n",
       "      <td>AUD</td>\n",
       "      <td>2017-04-23</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Fuzhou(FOC):2h40m</td>\n",
       "      <td>4</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>sydney</td>\n",
       "      <td>2017-04-30</td>\n",
       "      <td>21</td>\n",
       "      <td>flight_1_5_price</td>\n",
       "      <td>34</td>\n",
       "      <td>beijing</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>CX</td>\n",
       "      <td>[CX, CX]</td>\n",
       "      <td>2017-05-01T02:15:00.000+08:00</td>\n",
       "      <td>False</td>\n",
       "      <td>Cathay Pacific</td>\n",
       "      <td>2017-04-30T07:30:00.000+10:00</td>\n",
       "      <td>20h45m</td>\n",
       "      <td>CX110</td>\n",
       "      <td>110</td>\n",
       "      <td>78</td>\n",
       "      <td>AIRBUS INDUSTRIE A330-300</td>\n",
       "      <td>True</td>\n",
       "      <td>1001.79</td>\n",
       "      <td>AUD</td>\n",
       "      <td>2017-04-23</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Hong Kong(HKG):7h50m</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>sydney</td>\n",
       "      <td>2017-04-30</td>\n",
       "      <td>21</td>\n",
       "      <td>flight_1_5_price</td>\n",
       "      <td>34</td>\n",
       "      <td>beijing</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>QF</td>\n",
       "      <td>[QF]</td>\n",
       "      <td>2017-04-30T23:50:00.000+08:00</td>\n",
       "      <td>False</td>\n",
       "      <td>Qantas Airways</td>\n",
       "      <td>2017-04-30T11:20:00.000+10:00</td>\n",
       "      <td>14h30m</td>\n",
       "      <td>QF5005</td>\n",
       "      <td>5005</td>\n",
       "      <td>10</td>\n",
       "      <td>AIRBUS INDUSTRIE A330-200</td>\n",
       "      <td>False</td>\n",
       "      <td>825.24</td>\n",
       "      <td>AUD</td>\n",
       "      <td>2017-04-23</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Hangzhou(HGH):1h25m</td>\n",
       "      <td>9</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>sydney</td>\n",
       "      <td>2017-04-30</td>\n",
       "      <td>21</td>\n",
       "      <td>flight_1_5_price</td>\n",
       "      <td>34</td>\n",
       "      <td>beijing</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>MU</td>\n",
       "      <td>[MU, MU]</td>\n",
       "      <td>2017-05-22T07:40:00.000+10:00</td>\n",
       "      <td>False</td>\n",
       "      <td>China Eastern Airlines</td>\n",
       "      <td>2017-05-21T08:10:00.000+08:00</td>\n",
       "      <td>21h30m</td>\n",
       "      <td>MU2460</td>\n",
       "      <td>2460</td>\n",
       "      <td>20</td>\n",
       "      <td>Boeing 737-800</td>\n",
       "      <td>False</td>\n",
       "      <td>711.74</td>\n",
       "      <td>AUD</td>\n",
       "      <td>2017-04-23</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Wuhan(WUH):8h50m</td>\n",
       "      <td>9</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>sydney</td>\n",
       "      <td>2017-04-30</td>\n",
       "      <td>21</td>\n",
       "      <td>flight_1_5_price</td>\n",
       "      <td>34</td>\n",
       "      <td>beijing</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>CX</td>\n",
       "      <td>[CX, CX]</td>\n",
       "      <td>2017-04-30T21:30:00.000+08:00</td>\n",
       "      <td>False</td>\n",
       "      <td>Cathay Pacific</td>\n",
       "      <td>2017-04-30T07:30:00.000+10:00</td>\n",
       "      <td>16h0m</td>\n",
       "      <td>CX110</td>\n",
       "      <td>110</td>\n",
       "      <td>18</td>\n",
       "      <td>AIRBUS INDUSTRIE A330-300</td>\n",
       "      <td>True</td>\n",
       "      <td>952.04</td>\n",
       "      <td>AUD</td>\n",
       "      <td>2017-04-23</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Hong Kong(HKG):2h50m</td>\n",
       "      <td>9</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>sydney</td>\n",
       "      <td>2017-04-30</td>\n",
       "      <td>21</td>\n",
       "      <td>flight_1_5_price</td>\n",
       "      <td>34</td>\n",
       "      <td>beijing</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>CZ</td>\n",
       "      <td>[CZ, CZ]</td>\n",
       "      <td>2017-05-22T08:25:00.000+10:00</td>\n",
       "      <td>False</td>\n",
       "      <td>China Southern Airlines</td>\n",
       "      <td>2017-05-21T13:30:00.000+08:00</td>\n",
       "      <td>16h55m</td>\n",
       "      <td>CZ3106</td>\n",
       "      <td>3106</td>\n",
       "      <td>30</td>\n",
       "      <td>Airbus A321</td>\n",
       "      <td>False</td>\n",
       "      <td>891.44</td>\n",
       "      <td>AUD</td>\n",
       "      <td>2017-04-23</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Guangzhou(CAN):4h10m</td>\n",
       "      <td>6</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>sydney</td>\n",
       "      <td>2017-04-30</td>\n",
       "      <td>21</td>\n",
       "      <td>flight_1_5_price</td>\n",
       "      <td>34</td>\n",
       "      <td>beijing</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>MU</td>\n",
       "      <td>[MU]</td>\n",
       "      <td>2017-05-22T13:20:00.000+10:00</td>\n",
       "      <td>False</td>\n",
       "      <td>China Eastern Airlines</td>\n",
       "      <td>2017-05-21T23:45:00.000+08:00</td>\n",
       "      <td>11h35m</td>\n",
       "      <td>MU8420</td>\n",
       "      <td>8420</td>\n",
       "      <td>8</td>\n",
       "      <td>AIRBUS INDUSTRIE A330-200</td>\n",
       "      <td>False</td>\n",
       "      <td>989.74</td>\n",
       "      <td>AUD</td>\n",
       "      <td>2017-04-23</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>9</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>sydney</td>\n",
       "      <td>2017-04-30</td>\n",
       "      <td>21</td>\n",
       "      <td>flight_1_5_price</td>\n",
       "      <td>34</td>\n",
       "      <td>beijing</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>CX</td>\n",
       "      <td>[CX, CX]</td>\n",
       "      <td>2017-05-22T06:10:00.000+10:00</td>\n",
       "      <td>False</td>\n",
       "      <td>Cathay Pacific</td>\n",
       "      <td>2017-05-21T13:30:00.000+08:00</td>\n",
       "      <td>14h40m</td>\n",
       "      <td>CX391</td>\n",
       "      <td>391</td>\n",
       "      <td>40</td>\n",
       "      <td>772 - BOEING 777/200</td>\n",
       "      <td>True</td>\n",
       "      <td>952.04</td>\n",
       "      <td>AUD</td>\n",
       "      <td>2017-04-23</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Hong Kong(HKG):1h30m</td>\n",
       "      <td>4</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>sydney</td>\n",
       "      <td>2017-04-30</td>\n",
       "      <td>21</td>\n",
       "      <td>flight_1_5_price</td>\n",
       "      <td>34</td>\n",
       "      <td>beijing</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>CZ</td>\n",
       "      <td>[CZ, CZ]</td>\n",
       "      <td>2017-05-01T01:10:00.000+08:00</td>\n",
       "      <td>False</td>\n",
       "      <td>China Southern Airlines</td>\n",
       "      <td>2017-04-30T10:45:00.000+10:00</td>\n",
       "      <td>16h25m</td>\n",
       "      <td>CZ326</td>\n",
       "      <td>326</td>\n",
       "      <td>6</td>\n",
       "      <td>Airbus A330</td>\n",
       "      <td>False</td>\n",
       "      <td>681.44</td>\n",
       "      <td>AUD</td>\n",
       "      <td>2017-04-23</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Guangzhou(CAN):3h30m</td>\n",
       "      <td>5</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>sydney</td>\n",
       "      <td>2017-04-30</td>\n",
       "      <td>21</td>\n",
       "      <td>flight_1_5_price</td>\n",
       "      <td>34</td>\n",
       "      <td>beijing</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>QF</td>\n",
       "      <td>[QF]</td>\n",
       "      <td>2017-04-30T22:15:00.000+08:00</td>\n",
       "      <td>False</td>\n",
       "      <td>Qantas Airways</td>\n",
       "      <td>2017-04-30T12:25:00.000+10:00</td>\n",
       "      <td>11h50m</td>\n",
       "      <td>QF107</td>\n",
       "      <td>107</td>\n",
       "      <td>9</td>\n",
       "      <td>AIRBUS INDUSTRIE A330-200</td>\n",
       "      <td>False</td>\n",
       "      <td>800.24</td>\n",
       "      <td>AUD</td>\n",
       "      <td>2017-04-23</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>9</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>sydney</td>\n",
       "      <td>2017-04-30</td>\n",
       "      <td>21</td>\n",
       "      <td>flight_1_5_price</td>\n",
       "      <td>34</td>\n",
       "      <td>beijing</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>D7</td>\n",
       "      <td>[D7, D7]</td>\n",
       "      <td>2017-05-02T01:05:00.000+08:00</td>\n",
       "      <td>False</td>\n",
       "      <td>AirAsiaX</td>\n",
       "      <td>2017-04-30T21:25:00.000+10:00</td>\n",
       "      <td>29h40m</td>\n",
       "      <td>D7221</td>\n",
       "      <td>221</td>\n",
       "      <td>43</td>\n",
       "      <td></td>\n",
       "      <td>False</td>\n",
       "      <td>561.00</td>\n",
       "      <td>AUD</td>\n",
       "      <td>2017-04-23</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Kuala Lumpur(KUL):14h50m</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>sydney</td>\n",
       "      <td>2017-04-30</td>\n",
       "      <td>21</td>\n",
       "      <td>flight_1_5_price</td>\n",
       "      <td>34</td>\n",
       "      <td>beijing</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NZ</td>\n",
       "      <td>[NZ]</td>\n",
       "      <td>2017-05-21T14:50:00.000+10:00</td>\n",
       "      <td>False</td>\n",
       "      <td>Air New Zealand</td>\n",
       "      <td>2017-05-21T00:50:00.000+08:00</td>\n",
       "      <td>12h0m</td>\n",
       "      <td>NZ3883</td>\n",
       "      <td>3883</td>\n",
       "      <td>17</td>\n",
       "      <td>Airbus A330</td>\n",
       "      <td>False</td>\n",
       "      <td>2314.16</td>\n",
       "      <td>AUD</td>\n",
       "      <td>2017-04-23</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>7</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>sydney</td>\n",
       "      <td>2017-04-30</td>\n",
       "      <td>21</td>\n",
       "      <td>flight_1_5_price</td>\n",
       "      <td>34</td>\n",
       "      <td>beijing</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>VA</td>\n",
       "      <td>[VA, VA]</td>\n",
       "      <td>2017-05-01T07:15:00.000+08:00</td>\n",
       "      <td>False</td>\n",
       "      <td>Virgin Australia</td>\n",
       "      <td>2017-04-30T18:05:00.000+10:00</td>\n",
       "      <td>15h10m</td>\n",
       "      <td>VA5514</td>\n",
       "      <td>5514</td>\n",
       "      <td>35</td>\n",
       "      <td>BOEING 777-300ER</td>\n",
       "      <td>False</td>\n",
       "      <td>1747.84</td>\n",
       "      <td>AUD</td>\n",
       "      <td>2017-04-23</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Singapore(SIN):0h50m</td>\n",
       "      <td>4</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>sydney</td>\n",
       "      <td>2017-04-30</td>\n",
       "      <td>21</td>\n",
       "      <td>flight_1_5_price</td>\n",
       "      <td>34</td>\n",
       "      <td>beijing</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>CX</td>\n",
       "      <td>[CX, CX]</td>\n",
       "      <td>2017-04-30T22:30:00.000+08:00</td>\n",
       "      <td>False</td>\n",
       "      <td>Cathay Pacific</td>\n",
       "      <td>2017-04-30T10:05:00.000+10:00</td>\n",
       "      <td>14h25m</td>\n",
       "      <td>CX162</td>\n",
       "      <td>162</td>\n",
       "      <td>15</td>\n",
       "      <td>AIRBUS INDUSTRIE A330-300</td>\n",
       "      <td>True</td>\n",
       "      <td>952.04</td>\n",
       "      <td>AUD</td>\n",
       "      <td>2017-04-23</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Hong Kong(HKG):1h10m</td>\n",
       "      <td>4</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>sydney</td>\n",
       "      <td>2017-04-30</td>\n",
       "      <td>21</td>\n",
       "      <td>flight_1_5_price</td>\n",
       "      <td>34</td>\n",
       "      <td>beijing</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NH</td>\n",
       "      <td>[NH, NH]</td>\n",
       "      <td>2017-05-01T12:20:00.000+08:00</td>\n",
       "      <td>False</td>\n",
       "      <td>All Nippon Airways</td>\n",
       "      <td>2017-04-30T20:55:00.000+10:00</td>\n",
       "      <td>17h25m</td>\n",
       "      <td>NH880</td>\n",
       "      <td>880</td>\n",
       "      <td>37</td>\n",
       "      <td>BOEING 787-9</td>\n",
       "      <td>False</td>\n",
       "      <td>0.00</td>\n",
       "      <td></td>\n",
       "      <td>2017-04-23</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Tokyo(HND):4h0m</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>sydney</td>\n",
       "      <td>2017-04-30</td>\n",
       "      <td>21</td>\n",
       "      <td>flight_1_5_price</td>\n",
       "      <td>34</td>\n",
       "      <td>beijing</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>D7</td>\n",
       "      <td>[D7, D7]</td>\n",
       "      <td>2017-05-21T20:10:00.000+10:00</td>\n",
       "      <td>False</td>\n",
       "      <td>AirAsiaX</td>\n",
       "      <td>2017-05-21T02:15:00.000+08:00</td>\n",
       "      <td>15h55m</td>\n",
       "      <td>D7317</td>\n",
       "      <td>317</td>\n",
       "      <td>49</td>\n",
       "      <td></td>\n",
       "      <td>False</td>\n",
       "      <td>1001.79</td>\n",
       "      <td>AUD</td>\n",
       "      <td>2017-04-23</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Kuala Lumpur(KUL):1h35m</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>sydney</td>\n",
       "      <td>2017-04-30</td>\n",
       "      <td>21</td>\n",
       "      <td>flight_1_5_price</td>\n",
       "      <td>34</td>\n",
       "      <td>beijing</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>VN</td>\n",
       "      <td>[VN, CZ]</td>\n",
       "      <td>2017-05-01T05:45:00.000+08:00</td>\n",
       "      <td>False</td>\n",
       "      <td>Vietnam Airlines</td>\n",
       "      <td>2017-04-30T10:15:00.000+10:00</td>\n",
       "      <td>21h30m</td>\n",
       "      <td>VN772</td>\n",
       "      <td>772</td>\n",
       "      <td>34</td>\n",
       "      <td>Boeing 787</td>\n",
       "      <td>False</td>\n",
       "      <td>1578.64</td>\n",
       "      <td>AUD</td>\n",
       "      <td>2017-04-23</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Ho Chi Minh City(SGN):8h30m</td>\n",
       "      <td>4</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>sydney</td>\n",
       "      <td>2017-04-30</td>\n",
       "      <td>21</td>\n",
       "      <td>flight_1_5_price</td>\n",
       "      <td>34</td>\n",
       "      <td>beijing</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>CX</td>\n",
       "      <td>[CX, CX]</td>\n",
       "      <td>2017-05-01T11:40:00.000+08:00</td>\n",
       "      <td>False</td>\n",
       "      <td>Cathay Pacific</td>\n",
       "      <td>2017-04-30T21:55:00.000+10:00</td>\n",
       "      <td>15h45m</td>\n",
       "      <td>CX138</td>\n",
       "      <td>138</td>\n",
       "      <td>23</td>\n",
       "      <td>BOEING 777-300ER</td>\n",
       "      <td>False</td>\n",
       "      <td>952.04</td>\n",
       "      <td>AUD</td>\n",
       "      <td>2017-04-23</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Hong Kong(HKG):3h15m</td>\n",
       "      <td>4</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>sydney</td>\n",
       "      <td>2017-04-30</td>\n",
       "      <td>21</td>\n",
       "      <td>flight_1_5_price</td>\n",
       "      <td>34</td>\n",
       "      <td>beijing</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>MF</td>\n",
       "      <td>[MF, MF]</td>\n",
       "      <td>2017-05-22T09:15:00.000+10:00</td>\n",
       "      <td>False</td>\n",
       "      <td>Xiamen Airlines</td>\n",
       "      <td>2017-05-21T13:50:00.000+08:00</td>\n",
       "      <td>17h25m</td>\n",
       "      <td>MF8166</td>\n",
       "      <td>8166</td>\n",
       "      <td>21</td>\n",
       "      <td>Boeing 757</td>\n",
       "      <td>False</td>\n",
       "      <td>670.74</td>\n",
       "      <td>AUD</td>\n",
       "      <td>2017-04-23</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Fuzhou(FOC):5h5m</td>\n",
       "      <td>4</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>sydney</td>\n",
       "      <td>2017-04-30</td>\n",
       "      <td>21</td>\n",
       "      <td>flight_1_5_price</td>\n",
       "      <td>34</td>\n",
       "      <td>beijing</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>CX</td>\n",
       "      <td>[CX, CX]</td>\n",
       "      <td>2017-05-22T06:10:00.000+10:00</td>\n",
       "      <td>False</td>\n",
       "      <td>Cathay Pacific</td>\n",
       "      <td>2017-05-21T13:00:00.000+08:00</td>\n",
       "      <td>15h10m</td>\n",
       "      <td>CX6109</td>\n",
       "      <td>6109</td>\n",
       "      <td>46</td>\n",
       "      <td>AIRBUS INDUSTRIE A330-300</td>\n",
       "      <td>False</td>\n",
       "      <td>952.04</td>\n",
       "      <td>AUD</td>\n",
       "      <td>2017-04-23</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Hong Kong(HKG):2h25m</td>\n",
       "      <td>4</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>sydney</td>\n",
       "      <td>2017-04-30</td>\n",
       "      <td>21</td>\n",
       "      <td>flight_1_5_price</td>\n",
       "      <td>34</td>\n",
       "      <td>beijing</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>QF</td>\n",
       "      <td>[QF, CA]</td>\n",
       "      <td>2017-05-01T05:50:00.000+08:00</td>\n",
       "      <td>False</td>\n",
       "      <td>Qantas Airways</td>\n",
       "      <td>2017-04-30T17:45:00.000+10:00</td>\n",
       "      <td>14h5m</td>\n",
       "      <td>QF457</td>\n",
       "      <td>457</td>\n",
       "      <td>70</td>\n",
       "      <td>BOEING 737-800 (WINGLETS) PASSENGER</td>\n",
       "      <td>False</td>\n",
       "      <td>1673.14</td>\n",
       "      <td>AUD</td>\n",
       "      <td>2017-04-23</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Melbourne(MEL):1h20m</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>sydney</td>\n",
       "      <td>2017-04-30</td>\n",
       "      <td>21</td>\n",
       "      <td>flight_1_5_price</td>\n",
       "      <td>34</td>\n",
       "      <td>beijing</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>CZ</td>\n",
       "      <td>[CZ, CZ]</td>\n",
       "      <td>2017-05-01T18:15:00.000+08:00</td>\n",
       "      <td>False</td>\n",
       "      <td>China Southern Airlines</td>\n",
       "      <td>2017-04-30T21:45:00.000+10:00</td>\n",
       "      <td>22h30m</td>\n",
       "      <td>CZ302</td>\n",
       "      <td>302</td>\n",
       "      <td>66</td>\n",
       "      <td>Airbus A330</td>\n",
       "      <td>False</td>\n",
       "      <td>1332.69</td>\n",
       "      <td>AUD</td>\n",
       "      <td>2017-04-23</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Guangzhou(CAN):9h35m</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>sydney</td>\n",
       "      <td>2017-04-30</td>\n",
       "      <td>21</td>\n",
       "      <td>flight_1_5_price</td>\n",
       "      <td>34</td>\n",
       "      <td>beijing</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>MF</td>\n",
       "      <td>[MF, MF]</td>\n",
       "      <td>2017-05-01T09:50:00.000+08:00</td>\n",
       "      <td>False</td>\n",
       "      <td>Xiamen Airlines</td>\n",
       "      <td>2017-04-30T11:15:00.000+10:00</td>\n",
       "      <td>24h35m</td>\n",
       "      <td>MF802</td>\n",
       "      <td>802</td>\n",
       "      <td>5</td>\n",
       "      <td>Boeing 787</td>\n",
       "      <td>False</td>\n",
       "      <td>670.74</td>\n",
       "      <td>AUD</td>\n",
       "      <td>2017-04-23</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Xiamen(XMN):12h5m</td>\n",
       "      <td>4</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>sydney</td>\n",
       "      <td>2017-04-30</td>\n",
       "      <td>21</td>\n",
       "      <td>flight_1_5_price</td>\n",
       "      <td>34</td>\n",
       "      <td>beijing</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>QF</td>\n",
       "      <td>[QF, MU]</td>\n",
       "      <td>2017-04-30T23:40:00.000+08:00</td>\n",
       "      <td>False</td>\n",
       "      <td>Qantas Airways</td>\n",
       "      <td>2017-04-30T09:35:00.000+10:00</td>\n",
       "      <td>16h5m</td>\n",
       "      <td>QF129</td>\n",
       "      <td>129</td>\n",
       "      <td>60</td>\n",
       "      <td>AIRBUS INDUSTRIE A330-300</td>\n",
       "      <td>False</td>\n",
       "      <td>1217.29</td>\n",
       "      <td>AUD</td>\n",
       "      <td>2017-04-23</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Shanghai(PVG):2h45m</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>sydney</td>\n",
       "      <td>2017-04-30</td>\n",
       "      <td>21</td>\n",
       "      <td>flight_1_5_price</td>\n",
       "      <td>34</td>\n",
       "      <td>beijing</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>HU</td>\n",
       "      <td>[HU, MU]</td>\n",
       "      <td>2017-04-30T23:15:00.000+08:00</td>\n",
       "      <td>False</td>\n",
       "      <td>Hainan Airlines</td>\n",
       "      <td>2017-04-30T08:25:00.000+10:00</td>\n",
       "      <td>16h50m</td>\n",
       "      <td>HU7994</td>\n",
       "      <td>7994</td>\n",
       "      <td>54</td>\n",
       "      <td>Airbus A330</td>\n",
       "      <td>False</td>\n",
       "      <td>1190.29</td>\n",
       "      <td>AUD</td>\n",
       "      <td>2017-04-23</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Xi'an(XIY):3h30m</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>sydney</td>\n",
       "      <td>2017-04-30</td>\n",
       "      <td>21</td>\n",
       "      <td>flight_1_5_price</td>\n",
       "      <td>34</td>\n",
       "      <td>beijing</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>TG</td>\n",
       "      <td>[TG, TG]</td>\n",
       "      <td>2017-05-22T07:20:00.000+10:00</td>\n",
       "      <td>False</td>\n",
       "      <td>Thai Airways International</td>\n",
       "      <td>2017-05-21T05:55:00.000+08:00</td>\n",
       "      <td>23h25m</td>\n",
       "      <td>TG687</td>\n",
       "      <td>687</td>\n",
       "      <td>37</td>\n",
       "      <td>Boeing 787</td>\n",
       "      <td>False</td>\n",
       "      <td>914.24</td>\n",
       "      <td>AUD</td>\n",
       "      <td>2017-04-23</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Bangkok(BKK):9h15m</td>\n",
       "      <td>3</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>sydney</td>\n",
       "      <td>2017-04-30</td>\n",
       "      <td>21</td>\n",
       "      <td>flight_1_5_price</td>\n",
       "      <td>34</td>\n",
       "      <td>beijing</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>D7</td>\n",
       "      <td>[D7, D7]</td>\n",
       "      <td>2017-05-01T04:25:00.000+08:00</td>\n",
       "      <td>False</td>\n",
       "      <td>AirAsiaX</td>\n",
       "      <td>2017-04-30T11:00:00.000+10:00</td>\n",
       "      <td>19h25m</td>\n",
       "      <td>D7223</td>\n",
       "      <td>223</td>\n",
       "      <td>42</td>\n",
       "      <td></td>\n",
       "      <td>False</td>\n",
       "      <td>561.00</td>\n",
       "      <td>AUD</td>\n",
       "      <td>2017-04-23</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Kuala Lumpur(KUL):4h35m</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>sydney</td>\n",
       "      <td>2017-04-30</td>\n",
       "      <td>21</td>\n",
       "      <td>flight_1_5_price</td>\n",
       "      <td>34</td>\n",
       "      <td>beijing</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>SQ</td>\n",
       "      <td>[SQ, SQ]</td>\n",
       "      <td>2017-05-01T07:15:00.000+08:00</td>\n",
       "      <td>False</td>\n",
       "      <td>Singapore Airlines</td>\n",
       "      <td>2017-04-30T15:00:00.000+10:00</td>\n",
       "      <td>18h15m</td>\n",
       "      <td>SQ222</td>\n",
       "      <td>222</td>\n",
       "      <td>67</td>\n",
       "      <td>Airbus Industrie A380-800 Passenger</td>\n",
       "      <td>False</td>\n",
       "      <td>1127.39</td>\n",
       "      <td>AUD</td>\n",
       "      <td>2017-04-23</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Singapore(SIN):3h50m</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>sydney</td>\n",
       "      <td>2017-04-30</td>\n",
       "      <td>21</td>\n",
       "      <td>flight_1_5_price</td>\n",
       "      <td>34</td>\n",
       "      <td>beijing</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>FJ</td>\n",
       "      <td>[FJ, SQ]</td>\n",
       "      <td>2017-05-01T07:15:00.000+08:00</td>\n",
       "      <td>False</td>\n",
       "      <td>Fiji Airways</td>\n",
       "      <td>2017-04-30T10:25:00.000+10:00</td>\n",
       "      <td>22h50m</td>\n",
       "      <td>FJ5322</td>\n",
       "      <td>5322</td>\n",
       "      <td>72</td>\n",
       "      <td>AIRBUS INDUSTRIE A330-300</td>\n",
       "      <td>False</td>\n",
       "      <td>5552.39</td>\n",
       "      <td>AUD</td>\n",
       "      <td>2017-04-23</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Singapore(SIN):8h20m</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>sydney</td>\n",
       "      <td>2017-04-30</td>\n",
       "      <td>21</td>\n",
       "      <td>flight_1_5_price</td>\n",
       "      <td>34</td>\n",
       "      <td>beijing</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>QF</td>\n",
       "      <td>[QF, CA]</td>\n",
       "      <td>2017-05-01T05:50:00.000+08:00</td>\n",
       "      <td>False</td>\n",
       "      <td>Qantas Airways</td>\n",
       "      <td>2017-04-30T17:30:00.000+10:00</td>\n",
       "      <td>14h20m</td>\n",
       "      <td>QF455</td>\n",
       "      <td>455</td>\n",
       "      <td>64</td>\n",
       "      <td>BOEING 737-800 (WINGLETS) PASSENGER</td>\n",
       "      <td>False</td>\n",
       "      <td>1673.14</td>\n",
       "      <td>AUD</td>\n",
       "      <td>2017-04-23</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Melbourne(MEL):1h35m</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>sydney</td>\n",
       "      <td>2017-04-30</td>\n",
       "      <td>21</td>\n",
       "      <td>flight_1_5_price</td>\n",
       "      <td>34</td>\n",
       "      <td>beijing</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>CX</td>\n",
       "      <td>[CX, CX]</td>\n",
       "      <td>2017-04-30T20:25:00.000+08:00</td>\n",
       "      <td>False</td>\n",
       "      <td>Cathay Pacific</td>\n",
       "      <td>2017-04-30T07:30:00.000+10:00</td>\n",
       "      <td>14h55m</td>\n",
       "      <td>CX110</td>\n",
       "      <td>110</td>\n",
       "      <td>16</td>\n",
       "      <td>AIRBUS INDUSTRIE A330-300</td>\n",
       "      <td>True</td>\n",
       "      <td>952.04</td>\n",
       "      <td>AUD</td>\n",
       "      <td>2017-04-23</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Hong Kong(HKG):1h50m</td>\n",
       "      <td>9</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>sydney</td>\n",
       "      <td>2017-04-30</td>\n",
       "      <td>21</td>\n",
       "      <td>flight_1_5_price</td>\n",
       "      <td>34</td>\n",
       "      <td>beijing</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>SQ</td>\n",
       "      <td>[SQ, SQ]</td>\n",
       "      <td>2017-05-01T07:15:00.000+08:00</td>\n",
       "      <td>False</td>\n",
       "      <td>Singapore Airlines</td>\n",
       "      <td>2017-04-30T18:05:00.000+10:00</td>\n",
       "      <td>15h10m</td>\n",
       "      <td>SQ242</td>\n",
       "      <td>242</td>\n",
       "      <td>30</td>\n",
       "      <td>BOEING 777-300ER</td>\n",
       "      <td>False</td>\n",
       "      <td>1107.84</td>\n",
       "      <td>AUD</td>\n",
       "      <td>2017-04-23</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Singapore(SIN):0h50m</td>\n",
       "      <td>9</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>sydney</td>\n",
       "      <td>2017-04-30</td>\n",
       "      <td>21</td>\n",
       "      <td>flight_1_5_price</td>\n",
       "      <td>34</td>\n",
       "      <td>beijing</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>CX</td>\n",
       "      <td>[CX, KA]</td>\n",
       "      <td>2017-04-30T23:25:00.000+08:00</td>\n",
       "      <td>False</td>\n",
       "      <td>Cathay Pacific</td>\n",
       "      <td>2017-04-30T07:30:00.000+10:00</td>\n",
       "      <td>17h55m</td>\n",
       "      <td>CX110</td>\n",
       "      <td>110</td>\n",
       "      <td>76</td>\n",
       "      <td>AIRBUS INDUSTRIE A330-300</td>\n",
       "      <td>False</td>\n",
       "      <td>1001.79</td>\n",
       "      <td>AUD</td>\n",
       "      <td>2017-04-23</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Hong Kong(HKG):4h50m</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>sydney</td>\n",
       "      <td>2017-04-30</td>\n",
       "      <td>21</td>\n",
       "      <td>flight_1_5_price</td>\n",
       "      <td>34</td>\n",
       "      <td>beijing</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>CX</td>\n",
       "      <td>[CX, CX]</td>\n",
       "      <td>2017-05-01T20:25:00.000+08:00</td>\n",
       "      <td>False</td>\n",
       "      <td>Cathay Pacific</td>\n",
       "      <td>2017-04-30T21:55:00.000+10:00</td>\n",
       "      <td>24h30m</td>\n",
       "      <td>CX138</td>\n",
       "      <td>138</td>\n",
       "      <td>69</td>\n",
       "      <td>BOEING 777-300ER</td>\n",
       "      <td>True</td>\n",
       "      <td>1001.79</td>\n",
       "      <td>AUD</td>\n",
       "      <td>2017-04-23</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Hong Kong(HKG):11h45m</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>sydney</td>\n",
       "      <td>2017-04-30</td>\n",
       "      <td>21</td>\n",
       "      <td>flight_1_5_price</td>\n",
       "      <td>34</td>\n",
       "      <td>beijing</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>TG</td>\n",
       "      <td>[TG, TG]</td>\n",
       "      <td>2017-05-01T05:30:00.000+08:00</td>\n",
       "      <td>False</td>\n",
       "      <td>Thai Airways International</td>\n",
       "      <td>2017-04-30T16:00:00.000+10:00</td>\n",
       "      <td>15h30m</td>\n",
       "      <td>TG472</td>\n",
       "      <td>472</td>\n",
       "      <td>26</td>\n",
       "      <td>Boeing 747-400</td>\n",
       "      <td>False</td>\n",
       "      <td>914.24</td>\n",
       "      <td>AUD</td>\n",
       "      <td>2017-04-23</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Bangkok(BKK):1h30m</td>\n",
       "      <td>3</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>sydney</td>\n",
       "      <td>2017-04-30</td>\n",
       "      <td>21</td>\n",
       "      <td>flight_1_5_price</td>\n",
       "      <td>34</td>\n",
       "      <td>beijing</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>CZ</td>\n",
       "      <td>[CZ, CZ]</td>\n",
       "      <td>2017-05-01T19:15:00.000+08:00</td>\n",
       "      <td>False</td>\n",
       "      <td>China Southern Airlines</td>\n",
       "      <td>2017-04-30T21:45:00.000+10:00</td>\n",
       "      <td>23h30m</td>\n",
       "      <td>CZ302</td>\n",
       "      <td>302</td>\n",
       "      <td>52</td>\n",
       "      <td>Airbus A330</td>\n",
       "      <td>False</td>\n",
       "      <td>1332.69</td>\n",
       "      <td>AUD</td>\n",
       "      <td>2017-04-23</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Guangzhou(CAN):10h35m</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>sydney</td>\n",
       "      <td>2017-04-30</td>\n",
       "      <td>21</td>\n",
       "      <td>flight_1_5_price</td>\n",
       "      <td>34</td>\n",
       "      <td>beijing</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>CX</td>\n",
       "      <td>[CX, CX]</td>\n",
       "      <td>2017-04-30T22:30:00.000+08:00</td>\n",
       "      <td>False</td>\n",
       "      <td>Cathay Pacific</td>\n",
       "      <td>2017-04-30T07:30:00.000+10:00</td>\n",
       "      <td>17h0m</td>\n",
       "      <td>CX110</td>\n",
       "      <td>110</td>\n",
       "      <td>20</td>\n",
       "      <td>AIRBUS INDUSTRIE A330-300</td>\n",
       "      <td>True</td>\n",
       "      <td>952.04</td>\n",
       "      <td>AUD</td>\n",
       "      <td>2017-04-23</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Hong Kong(HKG):3h50m</td>\n",
       "      <td>9</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>sydney</td>\n",
       "      <td>2017-04-30</td>\n",
       "      <td>21</td>\n",
       "      <td>flight_1_5_price</td>\n",
       "      <td>34</td>\n",
       "      <td>beijing</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>CZ</td>\n",
       "      <td>[CZ, CZ]</td>\n",
       "      <td>2017-05-01T16:15:00.000+08:00</td>\n",
       "      <td>False</td>\n",
       "      <td>China Southern Airlines</td>\n",
       "      <td>2017-04-30T21:45:00.000+10:00</td>\n",
       "      <td>20h30m</td>\n",
       "      <td>CZ302</td>\n",
       "      <td>302</td>\n",
       "      <td>44</td>\n",
       "      <td>Airbus A330</td>\n",
       "      <td>False</td>\n",
       "      <td>1332.69</td>\n",
       "      <td>AUD</td>\n",
       "      <td>2017-04-23</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Guangzhou(CAN):7h35m</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>sydney</td>\n",
       "      <td>2017-04-30</td>\n",
       "      <td>21</td>\n",
       "      <td>flight_1_5_price</td>\n",
       "      <td>34</td>\n",
       "      <td>beijing</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>MH</td>\n",
       "      <td>[MH, MH]</td>\n",
       "      <td>2017-05-02T00:20:00.000+08:00</td>\n",
       "      <td>False</td>\n",
       "      <td>Malaysia Airlines</td>\n",
       "      <td>2017-04-30T22:10:00.000+10:00</td>\n",
       "      <td>28h10m</td>\n",
       "      <td>MH140</td>\n",
       "      <td>140</td>\n",
       "      <td>27</td>\n",
       "      <td>AIRBUS INDUSTRIE A330-300</td>\n",
       "      <td>False</td>\n",
       "      <td>1037.74</td>\n",
       "      <td>AUD</td>\n",
       "      <td>2017-04-23</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Kuala Lumpur(KUL):13h0m</td>\n",
       "      <td>3</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>sydney</td>\n",
       "      <td>2017-04-30</td>\n",
       "      <td>21</td>\n",
       "      <td>flight_1_5_price</td>\n",
       "      <td>34</td>\n",
       "      <td>beijing</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>CX</td>\n",
       "      <td>[CX, KA]</td>\n",
       "      <td>2017-04-30T21:20:00.000+08:00</td>\n",
       "      <td>False</td>\n",
       "      <td>Cathay Pacific</td>\n",
       "      <td>2017-04-30T07:30:00.000+10:00</td>\n",
       "      <td>15h50m</td>\n",
       "      <td>CX110</td>\n",
       "      <td>110</td>\n",
       "      <td>46</td>\n",
       "      <td>AIRBUS INDUSTRIE A330-300</td>\n",
       "      <td>False</td>\n",
       "      <td>1001.79</td>\n",
       "      <td>AUD</td>\n",
       "      <td>2017-04-23</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Hong Kong(HKG):2h20m</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>sydney</td>\n",
       "      <td>2017-04-30</td>\n",
       "      <td>21</td>\n",
       "      <td>flight_1_5_price</td>\n",
       "      <td>34</td>\n",
       "      <td>beijing</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>CX</td>\n",
       "      <td>[CX, CX]</td>\n",
       "      <td>2017-04-30T23:25:00.000+08:00</td>\n",
       "      <td>False</td>\n",
       "      <td>Cathay Pacific</td>\n",
       "      <td>2017-04-30T10:05:00.000+10:00</td>\n",
       "      <td>15h20m</td>\n",
       "      <td>CX162</td>\n",
       "      <td>162</td>\n",
       "      <td>22</td>\n",
       "      <td>AIRBUS INDUSTRIE A330-300</td>\n",
       "      <td>False</td>\n",
       "      <td>952.04</td>\n",
       "      <td>AUD</td>\n",
       "      <td>2017-04-23</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Hong Kong(HKG):2h10m</td>\n",
       "      <td>4</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>sydney</td>\n",
       "      <td>2017-04-30</td>\n",
       "      <td>21</td>\n",
       "      <td>flight_1_5_price</td>\n",
       "      <td>34</td>\n",
       "      <td>beijing</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>TG</td>\n",
       "      <td>[TG, TG]</td>\n",
       "      <td>2017-05-01T15:50:00.000+08:00</td>\n",
       "      <td>False</td>\n",
       "      <td>Thai Airways International</td>\n",
       "      <td>2017-04-30T16:00:00.000+10:00</td>\n",
       "      <td>25h50m</td>\n",
       "      <td>TG472</td>\n",
       "      <td>472</td>\n",
       "      <td>40</td>\n",
       "      <td>Boeing 747-400</td>\n",
       "      <td>False</td>\n",
       "      <td>1059.24</td>\n",
       "      <td>AUD</td>\n",
       "      <td>2017-04-23</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Bangkok(BKK):11h50m</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>sydney</td>\n",
       "      <td>2017-04-30</td>\n",
       "      <td>21</td>\n",
       "      <td>flight_1_5_price</td>\n",
       "      <td>34</td>\n",
       "      <td>beijing</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>HU</td>\n",
       "      <td>[HU, HU]</td>\n",
       "      <td>2017-04-30T22:00:00.000+08:00</td>\n",
       "      <td>False</td>\n",
       "      <td>Hainan Airlines</td>\n",
       "      <td>2017-04-30T08:25:00.000+10:00</td>\n",
       "      <td>15h35m</td>\n",
       "      <td>HU7994</td>\n",
       "      <td>7994</td>\n",
       "      <td>2</td>\n",
       "      <td>Airbus A330</td>\n",
       "      <td>False</td>\n",
       "      <td>559.04</td>\n",
       "      <td>AUD</td>\n",
       "      <td>2017-04-23</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Xi'an(XIY):2h10m</td>\n",
       "      <td>8</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>114 rows Ã 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    from_city_name  start_date stay_days        table_name task_id  \\\n",
       "0           sydney  2017-04-30        21  flight_1_5_price      34   \n",
       "1           sydney  2017-04-30        21  flight_1_5_price      34   \n",
       "2           sydney  2017-04-30        21  flight_1_5_price      34   \n",
       "3           sydney  2017-04-30        21  flight_1_5_price      34   \n",
       "4           sydney  2017-04-30        21  flight_1_5_price      34   \n",
       "5           sydney  2017-04-30        21  flight_1_5_price      34   \n",
       "6           sydney  2017-04-30        21  flight_1_5_price      34   \n",
       "7           sydney  2017-04-30        21  flight_1_5_price      34   \n",
       "8           sydney  2017-04-30        21  flight_1_5_price      34   \n",
       "9           sydney  2017-04-30        21  flight_1_5_price      34   \n",
       "10          sydney  2017-04-30        21  flight_1_5_price      34   \n",
       "11          sydney  2017-04-30        21  flight_1_5_price      34   \n",
       "12          sydney  2017-04-30        21  flight_1_5_price      34   \n",
       "13          sydney  2017-04-30        21  flight_1_5_price      34   \n",
       "14          sydney  2017-04-30        21  flight_1_5_price      34   \n",
       "15          sydney  2017-04-30        21  flight_1_5_price      34   \n",
       "16          sydney  2017-04-30        21  flight_1_5_price      34   \n",
       "17          sydney  2017-04-30        21  flight_1_5_price      34   \n",
       "18          sydney  2017-04-30        21  flight_1_5_price      34   \n",
       "19          sydney  2017-04-30        21  flight_1_5_price      34   \n",
       "20          sydney  2017-04-30        21  flight_1_5_price      34   \n",
       "21          sydney  2017-04-30        21  flight_1_5_price      34   \n",
       "22          sydney  2017-04-30        21  flight_1_5_price      34   \n",
       "23          sydney  2017-04-30        21  flight_1_5_price      34   \n",
       "24          sydney  2017-04-30        21  flight_1_5_price      34   \n",
       "25          sydney  2017-04-30        21  flight_1_5_price      34   \n",
       "26          sydney  2017-04-30        21  flight_1_5_price      34   \n",
       "27          sydney  2017-04-30        21  flight_1_5_price      34   \n",
       "28          sydney  2017-04-30        21  flight_1_5_price      34   \n",
       "29          sydney  2017-04-30        21  flight_1_5_price      34   \n",
       "..             ...         ...       ...               ...     ...   \n",
       "84          sydney  2017-04-30        21  flight_1_5_price      34   \n",
       "85          sydney  2017-04-30        21  flight_1_5_price      34   \n",
       "86          sydney  2017-04-30        21  flight_1_5_price      34   \n",
       "87          sydney  2017-04-30        21  flight_1_5_price      34   \n",
       "88          sydney  2017-04-30        21  flight_1_5_price      34   \n",
       "89          sydney  2017-04-30        21  flight_1_5_price      34   \n",
       "90          sydney  2017-04-30        21  flight_1_5_price      34   \n",
       "91          sydney  2017-04-30        21  flight_1_5_price      34   \n",
       "92          sydney  2017-04-30        21  flight_1_5_price      34   \n",
       "93          sydney  2017-04-30        21  flight_1_5_price      34   \n",
       "94          sydney  2017-04-30        21  flight_1_5_price      34   \n",
       "95          sydney  2017-04-30        21  flight_1_5_price      34   \n",
       "96          sydney  2017-04-30        21  flight_1_5_price      34   \n",
       "97          sydney  2017-04-30        21  flight_1_5_price      34   \n",
       "98          sydney  2017-04-30        21  flight_1_5_price      34   \n",
       "99          sydney  2017-04-30        21  flight_1_5_price      34   \n",
       "100         sydney  2017-04-30        21  flight_1_5_price      34   \n",
       "101         sydney  2017-04-30        21  flight_1_5_price      34   \n",
       "102         sydney  2017-04-30        21  flight_1_5_price      34   \n",
       "103         sydney  2017-04-30        21  flight_1_5_price      34   \n",
       "104         sydney  2017-04-30        21  flight_1_5_price      34   \n",
       "105         sydney  2017-04-30        21  flight_1_5_price      34   \n",
       "106         sydney  2017-04-30        21  flight_1_5_price      34   \n",
       "107         sydney  2017-04-30        21  flight_1_5_price      34   \n",
       "108         sydney  2017-04-30        21  flight_1_5_price      34   \n",
       "109         sydney  2017-04-30        21  flight_1_5_price      34   \n",
       "110         sydney  2017-04-30        21  flight_1_5_price      34   \n",
       "111         sydney  2017-04-30        21  flight_1_5_price      34   \n",
       "112         sydney  2017-04-30        21  flight_1_5_price      34   \n",
       "113         sydney  2017-04-30        21  flight_1_5_price      34   \n",
       "\n",
       "    to_city_name trip version airline_code airline_codes  \\\n",
       "0        beijing    2     1.0           CX      [CX, KA]   \n",
       "1        beijing    2     1.0           CX      [CX, KA]   \n",
       "2        beijing    2     1.0           CX      [CX, CX]   \n",
       "3        beijing    2     1.0           CZ      [CZ, CZ]   \n",
       "4        beijing    2     1.0           CX      [CX, CX]   \n",
       "5        beijing    2     1.0           NZ          [NZ]   \n",
       "6        beijing    2     1.0           VN      [VN, VN]   \n",
       "7        beijing    2     1.0           CX      [CX, KA]   \n",
       "8        beijing    2     1.0           FJ      [FJ, SQ]   \n",
       "9        beijing    2     1.0           CX      [CX, CX]   \n",
       "10       beijing    2     1.0           CZ      [CZ, CZ]   \n",
       "11       beijing    2     1.0           CZ      [CZ, CZ]   \n",
       "12       beijing    2     1.0           QF          [QF]   \n",
       "13       beijing    2     1.0           CZ      [CZ, CZ]   \n",
       "14       beijing    2     1.0           MU      [MU, MU]   \n",
       "15       beijing    2     1.0           CX      [CX, CX]   \n",
       "16       beijing    2     1.0           CX      [CX, KA]   \n",
       "17       beijing    2     1.0           MF      [MF, MF]   \n",
       "18       beijing    2     1.0           CX      [CX, CX]   \n",
       "19       beijing    2     1.0           QF          [QF]   \n",
       "20       beijing    2     1.0           MU      [MU, MU]   \n",
       "21       beijing    2     1.0           CX      [CX, CX]   \n",
       "22       beijing    2     1.0           CZ      [CZ, CZ]   \n",
       "23       beijing    2     1.0           MU          [MU]   \n",
       "24       beijing    2     1.0           CX      [CX, CX]   \n",
       "25       beijing    2     1.0           CZ      [CZ, CZ]   \n",
       "26       beijing    2     1.0           QF          [QF]   \n",
       "27       beijing    2     1.0           D7      [D7, D7]   \n",
       "28       beijing    2     1.0           NZ          [NZ]   \n",
       "29       beijing    2     1.0           VA      [VA, VA]   \n",
       "..           ...  ...     ...          ...           ...   \n",
       "84       beijing    2     1.0           CX      [CX, CX]   \n",
       "85       beijing    2     1.0           NH      [NH, NH]   \n",
       "86       beijing    2     1.0           D7      [D7, D7]   \n",
       "87       beijing    2     1.0           VN      [VN, CZ]   \n",
       "88       beijing    2     1.0           CX      [CX, CX]   \n",
       "89       beijing    2     1.0           MF      [MF, MF]   \n",
       "90       beijing    2     1.0           CX      [CX, CX]   \n",
       "91       beijing    2     1.0           QF      [QF, CA]   \n",
       "92       beijing    2     1.0           CZ      [CZ, CZ]   \n",
       "93       beijing    2     1.0           MF      [MF, MF]   \n",
       "94       beijing    2     1.0           QF      [QF, MU]   \n",
       "95       beijing    2     1.0           HU      [HU, MU]   \n",
       "96       beijing    2     1.0           TG      [TG, TG]   \n",
       "97       beijing    2     1.0           D7      [D7, D7]   \n",
       "98       beijing    2     1.0           SQ      [SQ, SQ]   \n",
       "99       beijing    2     1.0           FJ      [FJ, SQ]   \n",
       "100      beijing    2     1.0           QF      [QF, CA]   \n",
       "101      beijing    2     1.0           CX      [CX, CX]   \n",
       "102      beijing    2     1.0           SQ      [SQ, SQ]   \n",
       "103      beijing    2     1.0           CX      [CX, KA]   \n",
       "104      beijing    2     1.0           CX      [CX, CX]   \n",
       "105      beijing    2     1.0           TG      [TG, TG]   \n",
       "106      beijing    2     1.0           CZ      [CZ, CZ]   \n",
       "107      beijing    2     1.0           CX      [CX, CX]   \n",
       "108      beijing    2     1.0           CZ      [CZ, CZ]   \n",
       "109      beijing    2     1.0           MH      [MH, MH]   \n",
       "110      beijing    2     1.0           CX      [CX, KA]   \n",
       "111      beijing    2     1.0           CX      [CX, CX]   \n",
       "112      beijing    2     1.0           TG      [TG, TG]   \n",
       "113      beijing    2     1.0           HU      [HU, HU]   \n",
       "\n",
       "                          arr_time check_bag_inc                     company  \\\n",
       "0    2017-04-30T22:30:00.000+08:00         False              Cathay Pacific   \n",
       "1    2017-04-30T23:25:00.000+08:00         False              Cathay Pacific   \n",
       "2    2017-05-22T08:45:00.000+10:00         False              Cathay Pacific   \n",
       "3    2017-05-22T08:25:00.000+10:00         False     China Southern Airlines   \n",
       "4    2017-04-30T19:20:00.000+08:00         False              Cathay Pacific   \n",
       "5    2017-05-01T05:30:00.000+08:00         False             Air New Zealand   \n",
       "6    2017-05-22T12:15:00.000+10:00         False            Vietnam Airlines   \n",
       "7    2017-05-01T11:40:00.000+08:00         False              Cathay Pacific   \n",
       "8    2017-05-01T07:15:00.000+08:00         False                Fiji Airways   \n",
       "9    2017-05-22T08:45:00.000+10:00         False              Cathay Pacific   \n",
       "10   2017-05-01T15:15:00.000+08:00         False     China Southern Airlines   \n",
       "11   2017-05-01T12:15:00.000+08:00         False     China Southern Airlines   \n",
       "12   2017-05-22T13:20:00.000+10:00         False              Qantas Airways   \n",
       "13   2017-05-01T11:10:00.000+08:00         False     China Southern Airlines   \n",
       "14   2017-05-22T07:40:00.000+10:00         False      China Eastern Airlines   \n",
       "15   2017-05-01T12:20:00.000+08:00         False              Cathay Pacific   \n",
       "16   2017-04-30T22:30:00.000+08:00         False              Cathay Pacific   \n",
       "17   2017-05-22T09:15:00.000+10:00         False             Xiamen Airlines   \n",
       "18   2017-05-01T02:15:00.000+08:00         False              Cathay Pacific   \n",
       "19   2017-04-30T23:50:00.000+08:00         False              Qantas Airways   \n",
       "20   2017-05-22T07:40:00.000+10:00         False      China Eastern Airlines   \n",
       "21   2017-04-30T21:30:00.000+08:00         False              Cathay Pacific   \n",
       "22   2017-05-22T08:25:00.000+10:00         False     China Southern Airlines   \n",
       "23   2017-05-22T13:20:00.000+10:00         False      China Eastern Airlines   \n",
       "24   2017-05-22T06:10:00.000+10:00         False              Cathay Pacific   \n",
       "25   2017-05-01T01:10:00.000+08:00         False     China Southern Airlines   \n",
       "26   2017-04-30T22:15:00.000+08:00         False              Qantas Airways   \n",
       "27   2017-05-02T01:05:00.000+08:00         False                    AirAsiaX   \n",
       "28   2017-05-21T14:50:00.000+10:00         False             Air New Zealand   \n",
       "29   2017-05-01T07:15:00.000+08:00         False            Virgin Australia   \n",
       "..                             ...           ...                         ...   \n",
       "84   2017-04-30T22:30:00.000+08:00         False              Cathay Pacific   \n",
       "85   2017-05-01T12:20:00.000+08:00         False          All Nippon Airways   \n",
       "86   2017-05-21T20:10:00.000+10:00         False                    AirAsiaX   \n",
       "87   2017-05-01T05:45:00.000+08:00         False            Vietnam Airlines   \n",
       "88   2017-05-01T11:40:00.000+08:00         False              Cathay Pacific   \n",
       "89   2017-05-22T09:15:00.000+10:00         False             Xiamen Airlines   \n",
       "90   2017-05-22T06:10:00.000+10:00         False              Cathay Pacific   \n",
       "91   2017-05-01T05:50:00.000+08:00         False              Qantas Airways   \n",
       "92   2017-05-01T18:15:00.000+08:00         False     China Southern Airlines   \n",
       "93   2017-05-01T09:50:00.000+08:00         False             Xiamen Airlines   \n",
       "94   2017-04-30T23:40:00.000+08:00         False              Qantas Airways   \n",
       "95   2017-04-30T23:15:00.000+08:00         False             Hainan Airlines   \n",
       "96   2017-05-22T07:20:00.000+10:00         False  Thai Airways International   \n",
       "97   2017-05-01T04:25:00.000+08:00         False                    AirAsiaX   \n",
       "98   2017-05-01T07:15:00.000+08:00         False          Singapore Airlines   \n",
       "99   2017-05-01T07:15:00.000+08:00         False                Fiji Airways   \n",
       "100  2017-05-01T05:50:00.000+08:00         False              Qantas Airways   \n",
       "101  2017-04-30T20:25:00.000+08:00         False              Cathay Pacific   \n",
       "102  2017-05-01T07:15:00.000+08:00         False          Singapore Airlines   \n",
       "103  2017-04-30T23:25:00.000+08:00         False              Cathay Pacific   \n",
       "104  2017-05-01T20:25:00.000+08:00         False              Cathay Pacific   \n",
       "105  2017-05-01T05:30:00.000+08:00         False  Thai Airways International   \n",
       "106  2017-05-01T19:15:00.000+08:00         False     China Southern Airlines   \n",
       "107  2017-04-30T22:30:00.000+08:00         False              Cathay Pacific   \n",
       "108  2017-05-01T16:15:00.000+08:00         False     China Southern Airlines   \n",
       "109  2017-05-02T00:20:00.000+08:00         False           Malaysia Airlines   \n",
       "110  2017-04-30T21:20:00.000+08:00         False              Cathay Pacific   \n",
       "111  2017-04-30T23:25:00.000+08:00         False              Cathay Pacific   \n",
       "112  2017-05-01T15:50:00.000+08:00         False  Thai Airways International   \n",
       "113  2017-04-30T22:00:00.000+08:00         False             Hainan Airlines   \n",
       "\n",
       "                          dep_time duration flight_code flight_number  index  \\\n",
       "0    2017-04-30T10:05:00.000+10:00   14h25m       CX162           162     50   \n",
       "1    2017-04-30T10:05:00.000+10:00   15h20m       CX162           162     77   \n",
       "2    2017-05-21T15:30:00.000+08:00   15h15m      CX6115          6115     47   \n",
       "3    2017-05-21T14:30:00.000+08:00   15h55m      CZ3162          3162     29   \n",
       "4    2017-04-30T07:30:00.000+10:00   13h50m       CX110           110     14   \n",
       "5    2017-04-30T19:40:00.000+10:00   11h50m      NZ3884          3884     36   \n",
       "6    2017-05-21T15:45:00.000+08:00   18h30m       VN513           513     15   \n",
       "7    2017-04-30T21:55:00.000+10:00   15h45m       CX138           138     63   \n",
       "8    2017-04-30T15:50:00.000+10:00   17h25m      FJ5320          5320     49   \n",
       "9    2017-05-21T16:35:00.000+08:00   14h10m       CX331           331     38   \n",
       "10   2017-04-30T21:45:00.000+10:00   19h30m       CZ302           302     51   \n",
       "11   2017-04-30T21:45:00.000+10:00   16h30m       CZ302           302     13   \n",
       "12   2017-05-21T23:45:00.000+08:00   11h35m       QF108           108      5   \n",
       "13   2017-04-30T21:45:00.000+10:00   15h25m       CZ302           302     11   \n",
       "14   2017-05-21T11:30:00.000+08:00   18h10m      MU2452          2452      1   \n",
       "15   2017-04-30T21:55:00.000+10:00   16h25m       CX138           138     19   \n",
       "16   2017-04-30T07:30:00.000+10:00    17h0m       CX110           110     73   \n",
       "17   2017-05-21T16:20:00.000+08:00   14h55m      MF8108          8108      2   \n",
       "18   2017-04-30T07:30:00.000+10:00   20h45m       CX110           110     78   \n",
       "19   2017-04-30T11:20:00.000+10:00   14h30m      QF5005          5005     10   \n",
       "20   2017-05-21T08:10:00.000+08:00   21h30m      MU2460          2460     20   \n",
       "21   2017-04-30T07:30:00.000+10:00    16h0m       CX110           110     18   \n",
       "22   2017-05-21T13:30:00.000+08:00   16h55m      CZ3106          3106     30   \n",
       "23   2017-05-21T23:45:00.000+08:00   11h35m      MU8420          8420      8   \n",
       "24   2017-05-21T13:30:00.000+08:00   14h40m       CX391           391     40   \n",
       "25   2017-04-30T10:45:00.000+10:00   16h25m       CZ326           326      6   \n",
       "26   2017-04-30T12:25:00.000+10:00   11h50m       QF107           107      9   \n",
       "27   2017-04-30T21:25:00.000+10:00   29h40m       D7221           221     43   \n",
       "28   2017-05-21T00:50:00.000+08:00    12h0m      NZ3883          3883     17   \n",
       "29   2017-04-30T18:05:00.000+10:00   15h10m      VA5514          5514     35   \n",
       "..                             ...      ...         ...           ...    ...   \n",
       "84   2017-04-30T10:05:00.000+10:00   14h25m       CX162           162     15   \n",
       "85   2017-04-30T20:55:00.000+10:00   17h25m       NH880           880     37   \n",
       "86   2017-05-21T02:15:00.000+08:00   15h55m       D7317           317     49   \n",
       "87   2017-04-30T10:15:00.000+10:00   21h30m       VN772           772     34   \n",
       "88   2017-04-30T21:55:00.000+10:00   15h45m       CX138           138     23   \n",
       "89   2017-05-21T13:50:00.000+08:00   17h25m      MF8166          8166     21   \n",
       "90   2017-05-21T13:00:00.000+08:00   15h10m      CX6109          6109     46   \n",
       "91   2017-04-30T17:45:00.000+10:00    14h5m       QF457           457     70   \n",
       "92   2017-04-30T21:45:00.000+10:00   22h30m       CZ302           302     66   \n",
       "93   2017-04-30T11:15:00.000+10:00   24h35m       MF802           802      5   \n",
       "94   2017-04-30T09:35:00.000+10:00    16h5m       QF129           129     60   \n",
       "95   2017-04-30T08:25:00.000+10:00   16h50m      HU7994          7994     54   \n",
       "96   2017-05-21T05:55:00.000+08:00   23h25m       TG687           687     37   \n",
       "97   2017-04-30T11:00:00.000+10:00   19h25m       D7223           223     42   \n",
       "98   2017-04-30T15:00:00.000+10:00   18h15m       SQ222           222     67   \n",
       "99   2017-04-30T10:25:00.000+10:00   22h50m      FJ5322          5322     72   \n",
       "100  2017-04-30T17:30:00.000+10:00   14h20m       QF455           455     64   \n",
       "101  2017-04-30T07:30:00.000+10:00   14h55m       CX110           110     16   \n",
       "102  2017-04-30T18:05:00.000+10:00   15h10m       SQ242           242     30   \n",
       "103  2017-04-30T07:30:00.000+10:00   17h55m       CX110           110     76   \n",
       "104  2017-04-30T21:55:00.000+10:00   24h30m       CX138           138     69   \n",
       "105  2017-04-30T16:00:00.000+10:00   15h30m       TG472           472     26   \n",
       "106  2017-04-30T21:45:00.000+10:00   23h30m       CZ302           302     52   \n",
       "107  2017-04-30T07:30:00.000+10:00    17h0m       CX110           110     20   \n",
       "108  2017-04-30T21:45:00.000+10:00   20h30m       CZ302           302     44   \n",
       "109  2017-04-30T22:10:00.000+10:00   28h10m       MH140           140     27   \n",
       "110  2017-04-30T07:30:00.000+10:00   15h50m       CX110           110     46   \n",
       "111  2017-04-30T10:05:00.000+10:00   15h20m       CX162           162     22   \n",
       "112  2017-04-30T16:00:00.000+10:00   25h50m       TG472           472     40   \n",
       "113  2017-04-30T08:25:00.000+10:00   15h35m      HU7994          7994      2   \n",
       "\n",
       "                                   plane  power    price price_code  \\\n",
       "0              AIRBUS INDUSTRIE A330-300   True  1001.79        AUD   \n",
       "1              AIRBUS INDUSTRIE A330-300  False  1001.79        AUD   \n",
       "2                            Airbus A321  False   952.04        AUD   \n",
       "3                            Airbus A330  False   891.44        AUD   \n",
       "4              AIRBUS INDUSTRIE A330-300   True   952.04        AUD   \n",
       "5              AIRBUS INDUSTRIE A330-300  False  2314.16        AUD   \n",
       "6                             Boeing 787  False  1578.64        AUD   \n",
       "7                       BOEING 777-300ER  False  1001.79        AUD   \n",
       "8              AIRBUS INDUSTRIE A330-200  False  5552.39        AUD   \n",
       "9              AIRBUS INDUSTRIE A330-300   True   952.04        AUD   \n",
       "10                           Airbus A330  False  1332.69        AUD   \n",
       "11                           Airbus A330  False   891.44        AUD   \n",
       "12             AIRBUS INDUSTRIE A330-200  False   800.24        AUD   \n",
       "13                           Airbus A330  False   891.44        AUD   \n",
       "14   BOEING 737-800 (WINGLETS) PASSENGER  False   471.74        AUD   \n",
       "15                      BOEING 777-300ER   True   952.04        AUD   \n",
       "16             AIRBUS INDUSTRIE A330-300   True  1001.79        AUD   \n",
       "17                            Boeing 787  False   670.74        AUD   \n",
       "18             AIRBUS INDUSTRIE A330-300   True  1001.79        AUD   \n",
       "19             AIRBUS INDUSTRIE A330-200  False   825.24        AUD   \n",
       "20                        Boeing 737-800  False   711.74        AUD   \n",
       "21             AIRBUS INDUSTRIE A330-300   True   952.04        AUD   \n",
       "22                           Airbus A321  False   891.44        AUD   \n",
       "23             AIRBUS INDUSTRIE A330-200  False   989.74        AUD   \n",
       "24                  772 - BOEING 777/200   True   952.04        AUD   \n",
       "25                           Airbus A330  False   681.44        AUD   \n",
       "26             AIRBUS INDUSTRIE A330-200  False   800.24        AUD   \n",
       "27                                        False   561.00        AUD   \n",
       "28                           Airbus A330  False  2314.16        AUD   \n",
       "29                      BOEING 777-300ER  False  1747.84        AUD   \n",
       "..                                   ...    ...      ...        ...   \n",
       "84             AIRBUS INDUSTRIE A330-300   True   952.04        AUD   \n",
       "85                          BOEING 787-9  False     0.00              \n",
       "86                                        False  1001.79        AUD   \n",
       "87                            Boeing 787  False  1578.64        AUD   \n",
       "88                      BOEING 777-300ER  False   952.04        AUD   \n",
       "89                            Boeing 757  False   670.74        AUD   \n",
       "90             AIRBUS INDUSTRIE A330-300  False   952.04        AUD   \n",
       "91   BOEING 737-800 (WINGLETS) PASSENGER  False  1673.14        AUD   \n",
       "92                           Airbus A330  False  1332.69        AUD   \n",
       "93                            Boeing 787  False   670.74        AUD   \n",
       "94             AIRBUS INDUSTRIE A330-300  False  1217.29        AUD   \n",
       "95                           Airbus A330  False  1190.29        AUD   \n",
       "96                            Boeing 787  False   914.24        AUD   \n",
       "97                                        False   561.00        AUD   \n",
       "98   Airbus Industrie A380-800 Passenger  False  1127.39        AUD   \n",
       "99             AIRBUS INDUSTRIE A330-300  False  5552.39        AUD   \n",
       "100  BOEING 737-800 (WINGLETS) PASSENGER  False  1673.14        AUD   \n",
       "101            AIRBUS INDUSTRIE A330-300   True   952.04        AUD   \n",
       "102                     BOEING 777-300ER  False  1107.84        AUD   \n",
       "103            AIRBUS INDUSTRIE A330-300  False  1001.79        AUD   \n",
       "104                     BOEING 777-300ER   True  1001.79        AUD   \n",
       "105                       Boeing 747-400  False   914.24        AUD   \n",
       "106                          Airbus A330  False  1332.69        AUD   \n",
       "107            AIRBUS INDUSTRIE A330-300   True   952.04        AUD   \n",
       "108                          Airbus A330  False  1332.69        AUD   \n",
       "109            AIRBUS INDUSTRIE A330-300  False  1037.74        AUD   \n",
       "110            AIRBUS INDUSTRIE A330-300  False  1001.79        AUD   \n",
       "111            AIRBUS INDUSTRIE A330-300  False   952.04        AUD   \n",
       "112                       Boeing 747-400  False  1059.24        AUD   \n",
       "113                          Airbus A330  False   559.04        AUD   \n",
       "\n",
       "    search_date  span_days  stop                    stop_info  ticket_left  \\\n",
       "0    2017-04-23          0     1         Hong Kong(HKG):1h10m            0   \n",
       "1    2017-04-23          0     1         Hong Kong(HKG):2h10m            0   \n",
       "2    2017-04-23          0     1         Hong Kong(HKG):2h30m            4   \n",
       "3    2017-04-23          0     1         Guangzhou(CAN):3h10m            6   \n",
       "4    2017-04-23          0     1         Hong Kong(HKG):0h50m            9   \n",
       "5    2017-04-23          0     0                                         7   \n",
       "6    2017-04-23          0     1             Hanoi(HAN):5h30m            4   \n",
       "7    2017-04-23          0     1         Hong Kong(HKG):3h15m            0   \n",
       "8    2017-04-23          0     1         Singapore(SIN):2h55m            0   \n",
       "9    2017-04-23          0     1          Hong Kong(HKG):1h5m            9   \n",
       "10   2017-04-23          0     1         Guangzhou(CAN):6h35m            0   \n",
       "11   2017-04-23          0     1         Guangzhou(CAN):3h35m            6   \n",
       "12   2017-04-23          0     0                                         9   \n",
       "13   2017-04-23          0     1         Guangzhou(CAN):2h35m            6   \n",
       "14   2017-04-23          0     1             Wuhan(WUH):5h20m            9   \n",
       "15   2017-04-23          0     1         Hong Kong(HKG):3h45m            9   \n",
       "16   2017-04-23          0     1         Hong Kong(HKG):3h50m            0   \n",
       "17   2017-04-23          0     1            Fuzhou(FOC):2h40m            4   \n",
       "18   2017-04-23          0     1         Hong Kong(HKG):7h50m            0   \n",
       "19   2017-04-23          0     1          Hangzhou(HGH):1h25m            9   \n",
       "20   2017-04-23          0     1             Wuhan(WUH):8h50m            9   \n",
       "21   2017-04-23          0     1         Hong Kong(HKG):2h50m            9   \n",
       "22   2017-04-23          0     1         Guangzhou(CAN):4h10m            6   \n",
       "23   2017-04-23          0     0                                         9   \n",
       "24   2017-04-23          0     1         Hong Kong(HKG):1h30m            4   \n",
       "25   2017-04-23          0     1         Guangzhou(CAN):3h30m            5   \n",
       "26   2017-04-23          0     0                                         9   \n",
       "27   2017-04-23          0     1     Kuala Lumpur(KUL):14h50m            0   \n",
       "28   2017-04-23          0     0                                         7   \n",
       "29   2017-04-23          0     1         Singapore(SIN):0h50m            4   \n",
       "..          ...        ...   ...                          ...          ...   \n",
       "84   2017-04-23          0     1         Hong Kong(HKG):1h10m            4   \n",
       "85   2017-04-23          0     1              Tokyo(HND):4h0m            0   \n",
       "86   2017-04-23          0     1      Kuala Lumpur(KUL):1h35m            0   \n",
       "87   2017-04-23          0     1  Ho Chi Minh City(SGN):8h30m            4   \n",
       "88   2017-04-23          0     1         Hong Kong(HKG):3h15m            4   \n",
       "89   2017-04-23          0     1             Fuzhou(FOC):5h5m            4   \n",
       "90   2017-04-23          0     1         Hong Kong(HKG):2h25m            4   \n",
       "91   2017-04-23          0     1         Melbourne(MEL):1h20m            0   \n",
       "92   2017-04-23          0     1         Guangzhou(CAN):9h35m            0   \n",
       "93   2017-04-23          0     1            Xiamen(XMN):12h5m            4   \n",
       "94   2017-04-23          0     1          Shanghai(PVG):2h45m            0   \n",
       "95   2017-04-23          0     1             Xi'an(XIY):3h30m            0   \n",
       "96   2017-04-23          0     1           Bangkok(BKK):9h15m            3   \n",
       "97   2017-04-23          0     1      Kuala Lumpur(KUL):4h35m            0   \n",
       "98   2017-04-23          0     1         Singapore(SIN):3h50m            0   \n",
       "99   2017-04-23          0     1         Singapore(SIN):8h20m            0   \n",
       "100  2017-04-23          0     1         Melbourne(MEL):1h35m            0   \n",
       "101  2017-04-23          0     1         Hong Kong(HKG):1h50m            9   \n",
       "102  2017-04-23          0     1         Singapore(SIN):0h50m            9   \n",
       "103  2017-04-23          0     1         Hong Kong(HKG):4h50m            0   \n",
       "104  2017-04-23          0     1        Hong Kong(HKG):11h45m            0   \n",
       "105  2017-04-23          0     1           Bangkok(BKK):1h30m            3   \n",
       "106  2017-04-23          0     1        Guangzhou(CAN):10h35m            0   \n",
       "107  2017-04-23          0     1         Hong Kong(HKG):3h50m            9   \n",
       "108  2017-04-23          0     1         Guangzhou(CAN):7h35m            0   \n",
       "109  2017-04-23          0     1      Kuala Lumpur(KUL):13h0m            3   \n",
       "110  2017-04-23          0     1         Hong Kong(HKG):2h20m            0   \n",
       "111  2017-04-23          0     1         Hong Kong(HKG):2h10m            4   \n",
       "112  2017-04-23          0     1          Bangkok(BKK):11h50m            1   \n",
       "113  2017-04-23          0     1             Xi'an(XIY):2h10m            8   \n",
       "\n",
       "     video   wifi  \n",
       "0     True  False  \n",
       "1    False  False  \n",
       "2    False  False  \n",
       "3    False  False  \n",
       "4     True  False  \n",
       "5    False  False  \n",
       "6    False  False  \n",
       "7    False  False  \n",
       "8    False  False  \n",
       "9     True  False  \n",
       "10   False  False  \n",
       "11   False  False  \n",
       "12    True  False  \n",
       "13   False  False  \n",
       "14   False  False  \n",
       "15    True  False  \n",
       "16    True  False  \n",
       "17   False  False  \n",
       "18   False  False  \n",
       "19   False  False  \n",
       "20   False  False  \n",
       "21    True  False  \n",
       "22   False  False  \n",
       "23   False  False  \n",
       "24    True  False  \n",
       "25   False  False  \n",
       "26    True  False  \n",
       "27   False  False  \n",
       "28   False  False  \n",
       "29   False  False  \n",
       "..     ...    ...  \n",
       "84    True  False  \n",
       "85   False  False  \n",
       "86   False  False  \n",
       "87   False  False  \n",
       "88   False  False  \n",
       "89   False  False  \n",
       "90   False  False  \n",
       "91   False  False  \n",
       "92   False  False  \n",
       "93   False  False  \n",
       "94   False  False  \n",
       "95   False  False  \n",
       "96    True  False  \n",
       "97   False  False  \n",
       "98   False  False  \n",
       "99   False  False  \n",
       "100  False  False  \n",
       "101   True  False  \n",
       "102  False  False  \n",
       "103  False  False  \n",
       "104   True  False  \n",
       "105   True  False  \n",
       "106  False  False  \n",
       "107   True  False  \n",
       "108  False  False  \n",
       "109  False  False  \n",
       "110  False  False  \n",
       "111  False  False  \n",
       "112   True  False  \n",
       "113  False  False  \n",
       "\n",
       "[114 rows x 29 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# force to string\n",
    "# aggDF['id'] = 'Unknown'\n",
    "# aggDF['video'] = False\n",
    "# aggDF['wifi'] = False\n",
    "# aggDF['power'] = False\n",
    "aggDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+----------+---------+----------------+-------+------------+----+-------+------------+-------------+-----------------------------+-------------+--------------+-----------------------------+--------+-----------+-------------+-----+-------------------------+-----+-------+----------+-----------+---------+----+--------------------+-----------+-----+-----+\n",
      "|from_city_name|start_date|stay_days|table_name      |task_id|to_city_name|trip|version|airline_code|airline_codes|arr_time                     |check_bag_inc|company       |dep_time                     |duration|flight_code|flight_number|index|plane                    |power|price  |price_code|search_date|span_days|stop|stop_info           |ticket_left|video|wifi |\n",
      "+--------------+----------+---------+----------------+-------+------------+----+-------+------------+-------------+-----------------------------+-------------+--------------+-----------------------------+--------+-----------+-------------+-----+-------------------------+-----+-------+----------+-----------+---------+----+--------------------+-----------+-----+-----+\n",
      "|sydney        |2017-04-30|21       |flight_1_5_price|34     |beijing     |2   |1.0    |CX          |[CX, KA]     |2017-04-30T22:30:00.000+08:00|false        |Cathay Pacific|2017-04-30T10:05:00.000+10:00|14h25m  |CX162      |162          |50   |AIRBUS INDUSTRIE A330-300|true |1001.79|AUD       |2017-04-23 |0        |1   |Hong Kong(HKG):1h10m|0          |true |false|\n",
      "|sydney        |2017-04-30|21       |flight_1_5_price|34     |beijing     |2   |1.0    |CX          |[CX, KA]     |2017-04-30T23:25:00.000+08:00|false        |Cathay Pacific|2017-04-30T10:05:00.000+10:00|15h20m  |CX162      |162          |77   |AIRBUS INDUSTRIE A330-300|false|1001.79|AUD       |2017-04-23 |0        |1   |Hong Kong(HKG):2h10m|0          |false|false|\n",
      "+--------------+----------+---------+----------------+-------+------------+----+-------+------------+-------------+-----------------------------+-------------+--------------+-----------------------------+--------+-----------+-------------+-----+-------------------------+-----+-------+----------+-----------+---------+----+--------------------+-----------+-----+-----+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sp_df_test = spark.createDataFrame(aggDF)\n",
    "sp_df_test.show(2, truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create empty dataframe and save to empty parquet file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# if necessary delete the parquet file\n",
    "! rm -rf ~/s3/comb/flight_v1_0.pq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "struct_v1_0 = sp_df_test.schema\n",
    "emptyDF = spark.createDataFrame(sc.emptyRDD(), struct_v1_0)\n",
    "# emptyDF = spark.createDataFrame(aggDF, struct_v1_0)\n",
    "emptyDF.write.parquet(os.path.join(comb_fldr, \"flight_v1_0.pq\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 226\n",
      "226 453\n"
     ]
    }
   ],
   "source": [
    "len(range_temp)\n",
    "for chunk_num in range(0, 2):\n",
    "    print(str(range_temp[chunk_num][0]), str(range_temp[chunk_num][1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stopped here 20170521.  \n",
    "  \n",
    "**Need to**:   \n",
    "* test generating multip pandas df and read into spark and then parquet - DONE\n",
    "* build loop within flight_1_5 - DONE\n",
    "* build loop for different sub folders on s3\n",
    "\n",
    "**Problem**:   \n",
    "* need to figure out how to flatten nested spark dataframe - for now just do this in pandas\n",
    "\n",
    "Check out https://www.youtube.com/watch?v=noFkYVkixPA  \n",
    "and https://spark.apache.org/docs/2.1.1/sql-programming-guide.html#save-modes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/s3/comb/flight_v1_0.pq saved!\n",
      "/home/ubuntu/s3/comb/flight_v1_0.pq saved!\n",
      "/home/ubuntu/s3/comb/flight_v1_0.pq saved!\n",
      "/home/ubuntu/s3/comb/flight_v1_0.pq saved!\n",
      "/home/ubuntu/s3/comb/flight_v1_0.pq saved!\n",
      "/home/ubuntu/s3/comb/flight_v1_0.pq saved!\n",
      "/home/ubuntu/s3/comb/flight_v1_0.pq saved!\n",
      "/home/ubuntu/s3/comb/flight_v1_0.pq saved!\n",
      "/home/ubuntu/s3/comb/flight_v1_0.pq saved!\n",
      "/home/ubuntu/s3/comb/flight_v1_0.pq saved!\n"
     ]
    }
   ],
   "source": [
    "def append_pq(df):    \n",
    "    spDF = spark.createDataFrame(df, struct_v1_0)\n",
    "    spDF.repartition(1).write.mode('append').parquet(os.path.join(comb_fldr, \"flight_v1_0.pq\"))\n",
    "    print(os.path.join(comb_fldr, \"flight_v1_0.pq\") + \" saved!\")    \n",
    "    \n",
    "    \n",
    "file_count = len(glob.glob(os.path.join(ext_fldr, \"*.txt\")))\n",
    "range_temp = chunkIt(range(file_count), 100)\n",
    "\n",
    "for chunk_num in range(0, 10):\n",
    "    count = 0\n",
    "    aggDF = pd.DataFrame() #aggregate dataframe to hold all individual dataframes\n",
    "\n",
    "    for file in glob.glob(os.path.join(ext_fldr, \"*.txt\"))[range_temp[chunk_num][0]:range_temp[chunk_num][1]]:        \n",
    "        with open(file) as f:                           \n",
    "            d = json.load(f)\n",
    "            flight_list = json_normalize(d['flight_list'])\n",
    "            basic = json_normalize(d['basic'])\n",
    "\n",
    "            # create dataframe\n",
    "            basic = basic.drop('search_date', 1)\n",
    "            basic['tmp'] = 1\n",
    "            flight_list = flight_list.drop('id', 1)\n",
    "            flight_list['tmp'] = 1\n",
    "            DF = pd.merge(basic, flight_list, on=['tmp'])\n",
    "            DF=DF.drop('tmp', 1)\n",
    "            \n",
    "\n",
    "            # append\n",
    "            aggDF = aggDF.append(DF)\n",
    "            count = count + 1\n",
    "#             print(file+\" completed. Count: \" + str(count))        \n",
    "    append_pq(aggDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "flight = spark.read.parquet(\"/home/ubuntu/s3/comb/flight_v1_0.pq\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "68397"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flight.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "emptyDF.write.mode('append').parquet(os.path.join(comb_fldr, \"flight_v1_0.pq\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "! rm -rf /home/ubuntu/s3/flight_1_5/extracted/flight_1_5_price_2017-05-10_.pq\n",
    "# -f = to ignore non-existent files, never prompt\n",
    "# -r = to remove directories and their contents recursively\n",
    "# -v = to explain what is being done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "spark.createDataFrame(testDF2, struct_v1_1).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.show(2, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pyspark.sql.functions as F\n",
    "\n",
    "\n",
    "df1 = spark.read.json(os.path.join(comb_fldr, \"flight_1_5_price_2017-05-10_2017-06-10*.jsonl\"))\n",
    "df2 = spark.read.json(os.path.join(comb_fldr, \"flight_1_5_price_2017-05-10_2017-11-06_2_*.jsonl\"))\n",
    "df = df1.unionAll(df2)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# df.printSchema()\n",
    "# df.select(\"basic.*\").show()\n",
    "df.select(F.explode(\"flight_list\")).show(200, truncate=False)\n",
    "# df.select[\"basic\"]\n",
    "# flat_table = []  # a list\n",
    "# d = json.load(f)\n",
    "# flight_list = json_normalize(d['flight_list'])\n",
    "# basic = json_normalize(d['basic'])\n",
    "\n",
    "# # create dataframe\n",
    "# basic2 = basic.drop('search_date', 1)\n",
    "# basic2['tmp'] = 1\n",
    "# flight_list['tmp'] = 1\n",
    "# DF = pd.merge(basic2, flight_list, on=['tmp'])\n",
    "# DF=DF.drop('tmp', 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "basic2 = basic.drop('search_date', 1)\n",
    "basic2['tmp'] = 1\n",
    "flight_list['tmp'] = 1\n",
    "DF = pd.merge(basic2, flight_list, on=['tmp'])\n",
    "DF=DF.drop('tmp', 1)\n",
    "# DF.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "f = open(\"temp.jsonl\", \"w\")\n",
    "\n",
    "for row in DF.iterrows():\n",
    "    row[1].to_json(f)\n",
    "    f.write(\"\\n\")\n",
    "    \n",
    "f.close()\n",
    "\n",
    "open(\"temp.jsonl\").read()\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "flight = spark.read.json(\"/home/ubuntu/s3/comb/temp.jsonl\")\n",
    "flight.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "flight.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "data = []\n",
    "with open('/home/ubuntu/s3/comb/flight_1_5_price_2017-05-10_2017-11-06_2_7.jsonl') as f:\n",
    "    for line in f:\n",
    "        d = json.load(f)\n",
    "        flight_list = json_normalize(d['flight_list'])\n",
    "        basic = json_normalize(d['flight_list'])\n",
    "        flat_table = dict()\n",
    "        flat_table['basic'] = basic\n",
    "        flat_table['flight'] = flight_list\n",
    "        flat_table_list.append(flat_table)    \n",
    "df = pd.DataFrame.from_records(data)\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "! cd /home/ubuntu/s3/comb\n",
    "! head -n10 *.jsonl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(flat_table_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame.from_records(flat_table_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(jsonl_file_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Having errors. Probably due to 1 Gb RAM being too small to hold the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "flight = spark.read.json(jsonl_file_name)\n",
    "flight.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "flight.show(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "flight.write.parquet(pq_file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "flight.show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "extraction_path = \"/home/ubuntu/s3/flight_1_5/extracted\"\n",
    "\n",
    "\n",
    "\n",
    "d = read_from_json_file(json_file_name)\n",
    "\n",
    "jsonl_file_name = json_file_name.replace('.json','.jsonl')\n",
    "\n",
    "with open(jsonl_file_name,'w') as f:\n",
    "    json.dump(d, f)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import argparse\n",
    "import json\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# def spark_write(spark,jsonl_file_name,parquet_file_name):\n",
    "#     df = spark.read.json(jsonl_file_name)\n",
    "#     df.write.parquet(parquet_file_name)\n",
    "    \n",
    "# def spark_print_json(spark,json_file_name):\n",
    "#     d = read_from_json_file(json_file_name)\n",
    "    \n",
    "#     jsonl_file_name = json_file_name.replace('.json','.jsonl')\n",
    "    \n",
    "#     with open(jsonl_file_name,'w') as f:\n",
    "#         json.dump(d, f)\n",
    "    \n",
    "#     df = spark.read.json(jsonl_file_name)\n",
    "    \n",
    "#     df.createGlobalTempView(\"flight\")\n",
    "    \n",
    "#     spark.sql(\"SELECT fromCity,toCity,flight_leg1.departureTime, flight_leg1.departureLocation.airportLongName FROM global_temp.flight\").show()\n",
    "    \n",
    "def read_from_json_file(filename):\n",
    "    with open(filename,'r') as f:\n",
    "        d = json.load(f)\n",
    "        \n",
    "    return d\n",
    "\n",
    "# def pq_to_json_file(spark, pq_file_name, json_file_name):\n",
    "#     df = spark.read.load(pq_file_name)\n",
    "    \n",
    "#     df.write.json(json_file_name)\n",
    "    \n",
    "# def read_data_from_pq_file(spark,filename):\n",
    "#     df = spark.read.load(filename)\n",
    "    \n",
    "#     df.select('from_city_name','to_city_name').show()\n",
    "#     #spark.sql(\"SELECT from_city_name,to_city_name FROM global_temp.flight\").show()\n",
    "    \n",
    "# def main():\n",
    "#     full_path_pq_file_name = \"test/t.parquet\"\n",
    "\n",
    "#     spark = SparkSession \\\n",
    "#         .builder \\\n",
    "#         .appName(\"Python Spark SQL basic example\") \\\n",
    "#         .config(\"spark.some.config.option\", \"some-value\") \\\n",
    "#         .getOrCreate()\n",
    "            \n",
    "#     parser = argparse.ArgumentParser()\n",
    "    \n",
    "#     parser.add_argument('cmd',help='[json,pq,json2pq,jsonprint]')\n",
    "#     parser.add_argument('--json',help='json file namejson,pq]')\n",
    "#     parser.add_argument('--pq',help='parquet file name')\n",
    "    \n",
    "#     args = parser.parse_args()\n",
    "    \n",
    "#     cmd_ind = args.cmd\n",
    "#     json_file_name = args.json\n",
    "#     pq_file_name = args.pq\n",
    "    \n",
    "#     if cmd_ind == 'json2pq':\n",
    "#         if json_file_name is None:\n",
    "#             print(\"Please set the json file name by --json\")\n",
    "#             quit(0)\n",
    "            \n",
    "#         if pq_file_name is None:\n",
    "#             print(\"Please set the pqrquet file name by --pq\")\n",
    "#             quit(0)\n",
    "#         d = read_from_json_file(json_file_name)\n",
    "        \n",
    "#         jsonl_file_name = json_file_name.replace('.json','.jsonl')\n",
    "        \n",
    "#         with open(jsonl_file_name,'w') as f:\n",
    "#             json.dump(d, f)\n",
    "            \n",
    "#         spark_write(spark, jsonl_file_name, pq_file_name)\n",
    "#     elif cmd_ind == 'pq':\n",
    "#         if pq_file_name is None:\n",
    "#             print(\"Please set the pqrquet file name by --pq\")\n",
    "#             quit(0)\n",
    "#         read_data_from_pq_file(spark,full_path_pq_file_name)\n",
    "#     elif cmd_ind == 'pq2json':\n",
    "#         if json_file_name is None:\n",
    "#             print(\"Please set the json file name by --json\")\n",
    "#             quit(0)\n",
    "            \n",
    "#         if pq_file_name is None:\n",
    "#             print(\"Please set the pqrquet file name by --pq\")\n",
    "#             quit(0)\n",
    "            \n",
    "#         pq_to_json_file(spark,pq_file_name,json_file_name)\n",
    "        \n",
    "#     elif cmd_ind== 'jsonprint':\n",
    "#         if json_file_name is None:\n",
    "#             print(\"Please set the json file name by --json\")\n",
    "#             quit(0)\n",
    "            \n",
    "#         spark_print_json(spark,json_file_name)\n",
    "#     else:\n",
    "#         print('invalid cmd command')\n",
    "        \n",
    "#     spark.stop()\n",
    "    \n",
    "    \n",
    "# if __name__== '__main__':\n",
    "#     main()\n",
    "    \n",
    "    \n",
    "# spark-submit sp.py jsonprint --json final_flight_result_format_v1.1.json\n",
    "\n",
    "\n",
    "# json_file_name = \"D:\\\\Data Science\\\\pySpark\\\\test_schema\\\\final_flight_result_format_v1.1.json\"\n",
    "# jsonl_file_name = \"C:\\\\s3\\\\20170503_jsonl\\\\flight_1_6.jsonl\"\n",
    "jsonl_file_name = \"C:\\\\s3\\\\a3.json\"\n",
    "\n",
    "# d = read_from_json_file(json_file_name)\n",
    "\n",
    "# jsonl_file_name = json_file_name.replace('.json','.jsonl')\n",
    "\n",
    "# with open(jsonl_file_name,'w') as f:\n",
    "#     json.dump(d, f)\n",
    "\n",
    "# flight = spark.read.json(jsonl_file_name)\n",
    "\n",
    "# df.createGlobalTempView(\"flight\")\n",
    "\n",
    "# spark.sql(\"SELECT fromCity,toCity,flight_leg1.departureTime, flight_leg1.departureLocation.airportLongName FROM global_temp.flight\").show()\n",
    "  \n",
    "# flight.printSchema()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# flight.printSchema()\n",
    "# flight.drop('airline_codes').repartition(1).write.format('com.databricks.spark.csv').save('C:\\\\s3\\\\20170503_jsonl\\\\flight_1_6.csv', header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# flight.write.parquet(\"C:\\\\s3\\\\20170503_jsonl\\\\flight.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# flight = spark.read.parquet(\"C:\\\\s3\\\\20170503_jsonl\\\\flight.parquet\")\n",
    "flight = spark.read.parquet(\"/home/ubuntu/parquet/flight.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "flight.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "flight.printSchema()\n",
    "flight.show(2,truncate=False)\n",
    "display(flight.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# path_to_input = \"D:\\Data Science\\pySpark\\original_json\"\n",
    "# original_data = spark.read.json(sc.wholeTextFiles(path_to_input).values())\n",
    "\n",
    "# original_data = sqlContext.read.json(\"D:\\\\Data Science\\\\pySpark\\\\original_json\\\\original_flight_info.txt\")\n",
    "# original_data.printSchema()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import json\n",
    "# from pprint import pprint\n",
    "\n",
    "# # with open(\"D:\\\\Data Science\\\\pySpark\\\\original_json\\\\original_flight_info.txt\") as data_file:    \n",
    "# #     data = json.load(data_file)\n",
    "\n",
    "# # pprint(data)\n",
    "# # # data.head()\n",
    "\n",
    "# df = spark.read.json(\"D:\\\\Data Science\\\\Flight v2\\\\python\\\\final_flight_result_format_v1.1.json\")\n",
    "# # Displays the content of the DataFrame to stdout\n",
    "# df.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# flight = sc.textFile(\"C:\\\\s3_temp\\\\summary\\\\flat_table.csv\").map(lambda line: (line.split(',')[5], line.split(',')[10])).collect()\n",
    "# flight = sc.textFile(\"C:\\\\s3_temp\\\\summary\\\\flat_table.csv\")\n",
    "# flight = spark.read.csv(\"C:\\\\s3_temp\\\\summary\\\\flat_table.csv\", header=True, mode=\"DROPMALFORMED\")\n",
    "\n",
    "# flight.cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# flight.repartition(1).write.format('com.databricks.spark.csv').save('D://Data Science//pySpark//test2.csv', header=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "flight.first()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# flight.rdd.takeSample(False, 3, 1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "flight.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# from pyspark.sql.functions import year, month, dayofmonth, hour, minute, weekofyear, crosstab\n",
    "# flight2.select(year(\"arr_time\").alias('year'), \n",
    "# from pyspark.sql.functions import regexp_extract, col, split\n",
    "# # import re\n",
    "\n",
    "# from pyspark.sql.functions import udf\n",
    "# from pyspark.sql.types import IntegerType, StringType, BooleanType\n",
    "\n",
    "def toBool(aString):\n",
    "    if aString.lower() == 'true':\n",
    "        return True\n",
    "    else: \n",
    "        return False\n",
    " \n",
    "udfToBool = udf(toBool, BooleanType())\n",
    "\n",
    "\n",
    "def groupTicketLeft(aString):\n",
    "    if aString == '0':\n",
    "        return 'plenty'\n",
    "    else: \n",
    "        return aString\n",
    " \n",
    "udfGroupTicketLeft = udf(groupTicketLeft, StringType())\n",
    "\n",
    "# def getMinutes(aString):\n",
    "#     return minute(unix_timestamp(aString, \"HH'h'mm'm'\").cast(\"timestamp\"))\n",
    "\n",
    "# udfGetMinutes = udf(getMinutes, IntegerType())\n",
    "\n",
    "# def getHours(x):\n",
    "#   return re.match('([0-9]+(?=h))', x)\n",
    "# getHours(\"14h\")\n",
    "# len(flight.columns)\n",
    "# flight.columns\n",
    "# flight.dtypes\n",
    "flight2 = (flight.withColumn('search_date', flight.search_date.cast('timestamp'))\n",
    "#           .withColumn('search_date_y', flight.search_date_y.cast('timestamp'))\n",
    "#           .withColumnRenamed('search_date_y', 'search_date')\n",
    "          .withColumn('stay_days', flight.stay_days.cast('int'))                                \n",
    "           #create local time first\n",
    "           .withColumn('dep_time_local', flight.dep_time.substr(1, 23).cast('timestamp'))                      \n",
    "          .withColumn('dep_time', flight.dep_time.cast('timestamp'))\n",
    "           #create local time first\n",
    "          .withColumn('arr_time_local', flight.arr_time.substr(1, 23).cast('timestamp'))                      \n",
    "          .withColumn('arr_time', flight.arr_time.cast('timestamp'))\n",
    "           #duration           \n",
    "           .withColumn('duration_h',split(flight.duration,'h').getItem(0))\n",
    "           .withColumn('duration_m',split(flight.duration,'h').getItem(1))\n",
    "           #stop info\n",
    "           .withColumn('stop_info1',split(flight.stop_info,';').getItem(0))\n",
    "           .withColumn('stop_info2',split(flight.stop_info,';').getItem(1))\n",
    "#            .withColumn('druation_hours', \n",
    "#                        flight.selectExpr(\"duration\", \"regexp_extract(duration,'([0-9]+(?=h))', 1) as duration_hours\")\n",
    "#                        .duration_hours\n",
    "#                        .cast('int'))\n",
    "          .withColumn('start_date', flight.start_date.cast('date'))           \n",
    "          .withColumn('price', flight.price.cast('double'))          \n",
    "           # to correct the name\n",
    "          .withColumnRenamed('check_bag_inc', 'check_bag_not_inc')\n",
    "#           .withColumn('check_bag_not_inc', udfToBool(flight.check_bag_inc))\n",
    "          .withColumn('power', flight.power.cast('boolean'))           \n",
    "          .withColumn('video', flight.video.cast('boolean'))\n",
    "          .withColumn('wifi', flight.wifi.cast('boolean'))           \n",
    "          .withColumn('stop', flight.stop.cast('int')) \n",
    "          .withColumn('span_days', flight.span_days.cast('int'))           \n",
    "           .withColumn('ticket_left', udfGroupTicketLeft(flight.ticket_left))\n",
    "           .drop('search_date_x', 'check_bag_inc')\n",
    "          )\n",
    "\n",
    "flight2 = (flight2.withColumn('stop_loc1',split(flight2.stop_info1,':').getItem(0))\n",
    "           .withColumn('stop_duration1',split(flight2.stop_info1, ':').getItem(1))\n",
    "           .withColumn('stop_loc2',split(flight2.stop_info2,':').getItem(0))\n",
    "           .withColumn('stop_duration2',split(flight2.stop_info2, ':').getItem(1)))\n",
    "\n",
    "flight2 = (flight2.withColumn('stop_duration_h1',split(flight2.stop_duration1,'h').getItem(0))\n",
    "           .withColumn('stop_duration_m1',split(flight2.stop_duration1,'h').getItem(1))\n",
    "           .withColumn('stop_duration_h2',split(flight2.stop_duration2,'h').getItem(0))\n",
    "           .withColumn('stop_duration_m2',split(flight2.stop_duration2,'h').getItem(1)))\n",
    "# .withColumn('arr_time_zone', flight.arr_time.substr(24, 6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Define udf\n",
    "\n",
    "def getMinutes(hString, minString):\n",
    "    if (hString is not None) & (minString is not None): return int(hString) * 60 + int(minString[:-1])\n",
    "    else: return None\n",
    "#     if score >= 80: return 'A'\n",
    "#     elif score >= 60: return 'B'\n",
    "#     elif score >= 35: return 'C'\n",
    "#     else: return 'D'\n",
    " \n",
    "udfGetMinutes = udf(getMinutes, IntegerType())\n",
    "flight2 = (flight2.withColumn(\"duration_minutes\", udfGetMinutes(\"duration_h\", \"duration_m\"))\n",
    "                    .withColumn(\"stop1_minutes\", udfGetMinutes(\"stop_duration_h1\", \"stop_duration_m1\"))\n",
    "                   .withColumn(\"stop2_minutes\", udfGetMinutes(\"stop_duration_h2\", \"stop_duration_m2\")))\n",
    "                 \n",
    "flight2.show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# flight2.groupby('search_date', 'from_city_name', 'to_city_name', 'trip').count().show()\n",
    "# flight2.groupby('table_name').count().show()\n",
    "flight2.groupby('stop_info', \n",
    "                'stop_info1', 'stop_loc1', \n",
    "                'stop_duration1', 'stop_duration_h1', 'stop_duration_m1',\n",
    "                'stop_info2', 'stop_loc2', \n",
    "                'stop_duration2',  'stop_duration_h2', 'stop_duration_m2').count().show(500, truncate=False)\n",
    "# flight2.groupby('stop_duration1').count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "flight2.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# flight2 = flight2.drop('stop_duration_h1', 'stop_duration_m1', 'stop_duration_h2', 'stop_duration_m2',\n",
    "#                       'stop_duration1', 'stop_duration2',\n",
    "#                       'duration_h', 'duration_m', \n",
    "#                        'stop_info', 'stop_info1', 'stop_info2')\n",
    "# display(flight2.show(2))\n",
    "# display(flight2.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "flight2.show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def groupTime(dt):\n",
    "    h = dt.hour\n",
    "    if h < 5 : return 'early morning'    \n",
    "    elif h < 12 : return 'morning'\n",
    "    elif h < 18 : return 'afternoon'    \n",
    "    else: return 'evening'\n",
    "#     if h >= 18 or h < 7 : return 'night'    \n",
    "#     elif 7 <= h < 12 : return 'morning'\n",
    "#     elif 12 <= h < 18 : return 'afternoon'    \n",
    "#     else: return 'error'\n",
    "    \n",
    "    \n",
    "udfGroupTime = udf(groupTime, StringType())\n",
    "flight2 = flight2.withColumn(\"arr_time_group\", udfGroupTime(\"arr_time_local\")) \\\n",
    "                .withColumn(\"dep_time_group\", udfGroupTime(\"dep_time_local\"))              \n",
    "flight2.cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pyspark.sql.functions as F\n",
    "\n",
    "# flight2.select(\"dep_time_local\", \"dep_time_group\", \"arr_time_local\", \"arr_time_group\").show(10)\n",
    "#flight2.describe(['price']).show()# groupBy(\"dep_time_group\", \"arr_time_group\")\n",
    "# flight2.freqItems(flight2.trip)\n",
    "# flight2.groupby(flight2.trip, flight2.stay_days, flight.dep_time_group).agg(func.mean('price')).show()\n",
    "# flight2.groupby(flight2.trip, flight2.dep_time_group).agg(func.mean('price')).orderBy(['trip', 'avg(price)'], ascending=[1, 0]).show()\n",
    "# flight2.groupby(flight2.trip, flight2.company).agg(F.mean('price'), F.stddev('price'), F.max('price'), F.min('price')).orderBy(['trip', 'stddev_samp(price)'], ascending=[1, 0]).show(10000)\n",
    "flight2.filter(flight2.price <= 0).count() / flight2.count()\n",
    "\n",
    "# drop rows with zero price\n",
    "flight2 = flight2.filter(flight2.price > 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# duration_test.select(trim(col(\"duration\"))).show()\n",
    "# df\n",
    "# .withColumn('Created-formatted',when((df.Created.isNull() | (df.Created == '')) ,'0')\n",
    "# .otherwise(unix_timestamp(df.Created,'yyyy-MM-dd')))\n",
    "\n",
    "duration_test = flight2.select(\"stop_duration1\")\n",
    "duration_test.show()\n",
    "\n",
    "duration_test.withColumn('duration_h', when(duration_test.stop_duration1.isNull(), None)\n",
    "                          .otherwise(hour(unix_timestamp(duration_test.stop_duration1,\"HH'h'mm'm'\").cast(\"timestamp\")))).show(20)          \n",
    "    \n",
    "#     .withColumn('duration_m', minute(unix_timestamp(duration_test.duration,\"HH'h'mm'm'\").cast(\"timestamp\")))).show(2)\n",
    "\n",
    "\n",
    "# duration_test.withColumn('duration2',when((duration_test.duration.isNull() | (duration_test.duration == '')) , 0)\\\n",
    "#   .otherwise(unix_timestamp(duration_test.duration,\"HH'h'mm'm'\").cast(\"timestamp\"))).show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# from datetime import date\n",
    "\n",
    "# import holidays\n",
    "\n",
    "# us_holidays = holidays.UnitedStates()  # or holidays.US()\n",
    "\n",
    "# date(2015, 1, 1) in us_holidays  # True\n",
    "# date(2020, 12, 25) in us_holidays  # False\n",
    "\n",
    "# # print(us_holidays)\n",
    "\n",
    "\n",
    "# for date, name in sorted(holidays.AU(state='NSW', years=2017).items()):\n",
    "#      print(date, name)\n",
    "        \n",
    "# for date, name in sorted(holidays.NZ(state='AUK', years=2017).items()):\n",
    "#      print(date, name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# # The Holiday class will also recognize strings of any format\n",
    "# # and int/float representing a Unix timestamp\n",
    "# '2014-01-01' in us_holidays  # True\n",
    "# '1/1/2014' in us_holidays    # True\n",
    "# 1388597445 in us_holidays    # True\n",
    "\n",
    "# us_holidays.get('2014-01-01')  # \"New Year's Day\"\n",
    "\n",
    "# # Easily create custom Holiday objects with your own dates instead\n",
    "# # of using the pre-defined countries/states/provinces available\n",
    "# custom_holidays = holidays.HolidayBase()\n",
    "# # Append custom holiday dates by passing:\n",
    "# # 1) a dict with date/name key/value pairs,\n",
    "# custom_holidays.append({\"2015-01-01\": \"New Year's Day\"})\n",
    "# # 2) a list of dates (in any format: date, datetime, string, integer),\n",
    "# custom_holidays.append(['2015-07-01', '07/04/2015'])\n",
    "# # 3) a single date item\n",
    "# custom_holidays.append(date(2015, 12, 25))\n",
    "\n",
    "# date(2015, 1, 1) in custom_holidays  # True\n",
    "# date(2015, 1, 2) in custom_holidays  # False\n",
    "# '12/25/2015' in custom_holidays      # True\n",
    "\n",
    "# # For more complex logic like 4th Monday of January, you can inherit the\n",
    "# # HolidayBase class and define your own _populate(year) method. See below\n",
    "# # documentation for examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# from datetime import date\n",
    "# from workalendar.europe import France\n",
    "# cal = France()\n",
    "# cal.holidays(2017)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# flight2.show(2)\n",
    "flight3 = flight2\n",
    "\n",
    "\n",
    "def getWeekday(dt):\n",
    "    return dt.weekday()\n",
    "    \n",
    "def getWeeknumber(dt):\n",
    "    return dt.isocalendar()[1]\n",
    "\n",
    "    \n",
    "udfGetWeekday = udf(getWeekday, StringType())\n",
    "udfGetWeeknumber = udf(getWeeknumber, IntegerType())\n",
    "\n",
    "flight3 = flight3.withColumn(\"dep_weekday\", udfGetWeekday(\"start_date\")) \\\n",
    "                .withColumn(\"dep_weeknum\", udfGetWeeknumber(\"start_date\")) \\\n",
    "                .withColumn(\"lead_time\", datediff(flight3.start_date, flight3.search_date)) \n",
    "#                 .drop('start_date', 'search_date')\n",
    "\n",
    "flight3.show(2)\n",
    "display(flight2.count(), flight3.count())\n",
    "flight3.describe('lead_time').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "flight3.show(5)\n",
    "flight3.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "get distance to nearest holiday: http://stackoverflow.com/questions/40752378/spark-sql-distance-to-nearest-holiday\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# datetime.datetime('2017-09-01')\n",
    "# date1 = datetime.datetime.strptime(\"2015-01-30\", \"%Y-%m-%d\").strftime(\"%d-%m-%Y\")\n",
    "# print(date1)\n",
    "# start_date_test = flight3.select(\"start_date\").distinct()\n",
    "flight3 = flight3.withColumn(\"start_date_str\", flight3.start_date.cast('string'))\n",
    "\n",
    "holidays = ['2017-01-01', '2017-01-02', '2017-01-27', '2017-01-28',\n",
    "            '2017-01-29', '2017-01-30', '2017-01-31', '2017-02-01', '2017-02-02',\n",
    "            '2017-04-02', '2017-04-03', '2017-04-04',\n",
    "            '2017-05-01', '2017-05-28', '2017-05-29', '2017-05-30',\n",
    "            '2017-10-01', '2017-10-02', '2017-10-03', '2017-10-04', '217-10-05', '2017-10-06']\n",
    " \n",
    "\n",
    "index = spark.sparkContext.broadcast(sorted(holidays))\n",
    "\n",
    "def last_holiday(date):\n",
    "    last_holiday = index.value[0]\n",
    "    for next_holiday in index.value:\n",
    "        if next_holiday >= date:\n",
    "            break\n",
    "        last_holiday = next_holiday\n",
    "    if last_holiday > date:\n",
    "        last_holiday = None\n",
    "    if next_holiday < date:\n",
    "        next_holiday = None        \n",
    "    return last_holiday\n",
    "\n",
    "def next_holiday(date):\n",
    "    last_holiday = index.value[0]\n",
    "    for next_holiday in index.value:\n",
    "        if next_holiday >= date:\n",
    "            break\n",
    "        last_holiday = next_holiday\n",
    "    if last_holiday > date:\n",
    "        last_holiday = None\n",
    "    if next_holiday < date:\n",
    "        next_holiday = None        \n",
    "    return next_holiday\n",
    "\n",
    "\n",
    "# return_type = StructType([StructField('last_holiday', StringType()), StructField('next_holiday', StringType())])\n",
    "\n",
    "last_holiday_udf = udf(last_holiday, StringType())\n",
    "next_holiday_udf = udf(next_holiday, StringType())\n",
    "\n",
    "flight4 = flight3.withColumn('last_holiday', last_holiday_udf('start_date_str'))\n",
    "flight4 = flight4.withColumn('next_holiday', next_holiday_udf('start_date_str'))\n",
    "flight4 = flight4.withColumn('days_to_last_holiday', datediff('last_holiday', 'start_date_str'))\n",
    "flight4 = flight4.withColumn('days_to_next_holiday', datediff('next_holiday', 'start_date_str'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "(flight4\n",
    "    .select('days_to_last_holiday', 'days_to_next_holiday', 'last_holiday', 'next_holiday', 'start_date')    \n",
    "    .distinct().show())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# flight4.show()\n",
    "#'table_name', 'trip', 'stay_days'\n",
    "# flight5 = (flight4.filter((flight4.trip==1) & (flight4.start_date=='2017-10-01') & (flight4.company=='AirAsiaX'))\n",
    "#          .select('start_date', 'company', 'dep_time_local', 'stop_info', 'duration', 'search_date', 'price')\n",
    "#          .sort(F.desc('start_date'), 'company', 'dep_time_local', 'stop_info', 'duration', 'search_date'))       \n",
    "         \n",
    "flight5 = flight4.sort('table_name', 'trip', 'stay_days', \n",
    "                       'start_date', 'company', 'dep_time_local',\n",
    "                       'stop_info', 'duration', 'search_date')       \n",
    "    \n",
    "byVar = ['table_name', 'trip', 'stay_days', 'start_date', 'company', 'dep_time_local', 'stop_info', 'duration']\n",
    "\n",
    "\n",
    "from pyspark.sql.window import Window\n",
    "\n",
    "Threshold = 5\n",
    "\n",
    "w =  Window.partitionBy(byVar).orderBy('search_date').rowsBetween(0, sys.maxsize)\n",
    "flight6 = (flight5.withColumn('future_min_price', F.min(col('price')).over(w))\n",
    "          .withColumn('price_will_drop',                       \n",
    "                      (col('price') - col('future_min_price')) > Threshold ))\n",
    "flight6 = flight6.withColumn('price_will_drop_num', flight6.price_will_drop.cast('int'))\n",
    "flight6.cache()\n",
    "# min_price = (flight5\n",
    "#                   .groupBy(byVar)\n",
    "#                   .agg(F.min(col(\"price\"))).alias(\"min_price\"))\n",
    "\n",
    "# flight6 = flight5.join(min_price, on=byVar, how='left')\n",
    "# # flight6.select('price', 'min(price)').show(10)\n",
    "# # flight6.select('price', 'min(price)').show()\n",
    "# flight6 = flight6.withColumn('price_diff', col('price')-col('min(price)'))\n",
    "# flight6.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "flight6.filter((flight6.trip==1) & \\\n",
    "               (flight6.start_date=='2017-10-01') & \\\n",
    "               (flight6.company=='AirAsiaX')) \\\n",
    "    .select('duration', 'search_date', 'price', 'future_min_price', 'price_will_drop') \\\n",
    "    .show(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "flight2.unpersist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "flight6.cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# ['table_name', 'trip', 'stay_days', 'start_date', 'company', 'dep_time_local', 'stop_info', 'duration']\n",
    "# groupby(flight2.trip, flight2.stay_days, flight.dep_time_group).agg(func.mean('price')).show()\n",
    "# flight6.groupBy(col('trip'), col('stay_days'), col('lead_time')).agg(F.mean('price_will_drop_num')).show()\n",
    "flight6.groupBy(col('trip'), col('stay_days'), col('lead_time')). \\\n",
    "    agg(F.mean('price_will_drop_num')).orderBy(['trip', 'stay_days', 'lead_time'], ascending=[1, 1, 0]).show(1000)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save to parquet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "flight6.coalesce(2).write.parquet(\"C:\\\\s3\\\\20170503_jsonl\\\\flight6.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# flight6 = spark.read.parquet(\"C:\\\\s3\\\\20170503_jsonl\\\\flight6.parquet\")\n",
    "flight6 = spark.read.parquet(\"/home/ubuntu/parquet/flight6.parquet\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "flight6.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "flight6.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "flight7 = (flight6.withColumn('price_drop_amt', col('price') - col('future_min_price'))\n",
    "                  .withColumn('stop_minutes', col('stop1_minutes') + col('stop2_minutes'))\n",
    "                  .withColumn('few_tickets_left', col('ticket_left') != '0')\n",
    "                  .select('price_will_drop_num', 'price', 'few_tickets_left', 'from_city_name', 'to_city_name', 'trip', 'stay_days',\n",
    "                          'company', 'flight_code', 'plane', 'span_days', 'stop',\n",
    "                         'power', 'video', 'wifi', 'check_bag_not_inc', \n",
    "                         'dep_time_group', 'arr_time_group',  \n",
    "                         'lead_time', 'dep_weekday', 'dep_weeknum', \n",
    "                         'days_to_last_holiday', 'days_to_next_holiday',                         \n",
    "                         'duration_minutes', 'stop_minutes'\n",
    "                      ).filter(flight6.price > 0))\n",
    "flight7.dtypes\n",
    "flight7 = flight7.na.fill({'stop_minutes': 0, 'days_to_next_holiday': 999})\n",
    "flight7.show(2, truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How to transform categorical variables? See\n",
    "http://stackoverflow.com/questions/32982425/encode-and-assemble-multiple-features-in-pyspark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# One hot encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import StringIndexer\n",
    "from pyspark.ml.feature import OneHotEncoder\n",
    "\n",
    "column_vec_in = ['from_city_name', 'to_city_name', 'trip', 'company', 'flight_code', 'plane', \n",
    "                 'arr_time_group', 'dep_time_group', 'dep_weekday']\n",
    "column_vec_out = ['from_city_name_catVec','to_city_name_catVec', 'trip_catVec',\n",
    "                'company_catVec', 'flight_code_catVec', 'plane_catVec', \n",
    "                  'arr_time_group_catVec', 'dep_time_group_catVec', 'dep_weekday_catVec']\n",
    " \n",
    "indexers = [StringIndexer(inputCol=x, outputCol=x+'_tmp') for x in column_vec_in ]\n",
    " \n",
    "encoders = [OneHotEncoder(dropLast=False, inputCol=x+\"_tmp\", outputCol=y)\n",
    "            for x,y in zip(column_vec_in, column_vec_out)]\n",
    "\n",
    "tmp = [[i,j] for i,j in zip(indexers, encoders)]\n",
    "tmp = [i for sublist in tmp for i in sublist]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare features and labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.feature import StringIndexer, VectorIndexer, VectorAssembler, SQLTransformer\n",
    "\n",
    "# prepare labeled sets\n",
    "# 'price_will_drop',\n",
    "\n",
    "cols_now = ['price', 'few_tickets_left', 'stay_days',\n",
    "              'span_days', 'stop',\n",
    "             'power', 'video', 'wifi', 'check_bag_not_inc',                          \n",
    "             'lead_time', 'dep_weeknum', \n",
    "             'days_to_last_holiday', 'days_to_next_holiday',                         \n",
    "             'duration_minutes', 'stop_minutes',\n",
    "            'from_city_name_catVec','to_city_name_catVec', 'trip_catVec',\n",
    "            'company_catVec', 'flight_code_catVec', 'plane_catVec', \n",
    "            'arr_time_group_catVec', 'dep_time_group_catVec', 'dep_weekday_catVec']\n",
    "\n",
    "assembler_features = VectorAssembler(inputCols=cols_now, outputCol='features')\n",
    "# labelIndexer = StringIndexer(inputCol='price', outputCol=\"label\")\n",
    "# tmp += [assembler_features, labelIndexer]\n",
    "tmp += [assembler_features]\n",
    "pipeline = Pipeline(stages=tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# flight3.na.drop().count()\n",
    "\n",
    "# from pyspark.ml import Pipeline\n",
    "# from pyspark.ml.feature import StringIndexer\n",
    "\n",
    "# indexers = [StringIndexer(inputCol=column, outputCol=column+\"_index\")\\\n",
    "#             .fit(flight3) for column in list(set(flight3.columns)-\\\n",
    "#                                              set(['stay_days', 'power', 'price', 'span_days',\\\n",
    "#                                                   'stop', 'video', 'wifi', 'duration_minutes',\\\n",
    "#                                                  'dep_weeknum', 'lead_time']))]\n",
    "\n",
    "# pipeline = Pipeline(stages=indexers)\n",
    "# flight4 = pipeline.fit(flight3).transform(flight3)\n",
    "\n",
    "# flight4.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cols = ['from_city_name', 'to_city_name', 'trip', 'company', 'flight_code', 'plane', \n",
    "                 'arr_time_group', 'dep_time_group', 'dep_weekday']\n",
    "\n",
    "for c in cols:\n",
    "    flight7.groupBy(col(c)).count().show(50000)\n",
    "    \n",
    "    \n",
    "flight7 = flight7.na.replace('', 'unknown', 'plane')\n",
    "\n",
    "# http://stackoverflow.com/questions/40711229/pyspark-ml-error-urequirement-failed-cannot-have-an-empty-string-for-name\n",
    "# replacements = {\n",
    "#   'plane': 'unknown', 'another_col': 'another_replacement',\n",
    "#   'numeric_column_wont_be_replaced': 1.0\n",
    "# }\n",
    "\n",
    "# for k, v in replacements.items():\n",
    "#     # We can replace string only if target is string\n",
    "#     # In Python 2 str -> basestring\n",
    "#     if isinstance(v, str):\n",
    "#         df = df.na.replace(\"\", v, [k])        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cols = ['price_will_drop', 'price', 'few_tickets_left', 'from_city_name', 'to_city_name', 'trip', 'stay_days',\n",
    "                          'company', 'flight_code', 'plane', 'span_days', 'stop',\n",
    "                         'power', 'video', 'wifi', 'check_bag_not_inc', \n",
    "                         'dep_time_group', 'arr_time_group',  \n",
    "                         'lead_time', 'dep_weekday', 'dep_weeknum', \n",
    "                         'days_to_last_holiday', 'days_to_next_holiday',                         \n",
    "                         'duration_minutes', 'stop_minutes']\n",
    "\n",
    "for c in cols:\n",
    "    display(c + \" :\" + str(flight7.where(col(c).isNull()).count()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "flight7.show(2)\n",
    "flight7.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# flight7 = flight7.na.drop()\n",
    "output = pipeline.fit(flight7).transform(flight7)\n",
    "output = output.withColumnRenamed('price_will_drop_num', 'label')\n",
    "output.cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "output.show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# flight4.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# flight4.select('stay_days',\n",
    "#  'power', \n",
    "#  'span_days',\n",
    "#  'stop',\n",
    "#  'video',\n",
    "#  'wifi',\n",
    "#  'duration_minutes',\n",
    "#  'dep_weeknum',\n",
    "#  'lead_time',\n",
    "#  'trip_index',\n",
    "#  'arr_time_group_index',\n",
    "#  'to_city_name_index',\n",
    "#  'ticket_left_index',\n",
    "#  'company_index',\n",
    "#  'from_city_name_index',\n",
    "#  'airline_code_index',\n",
    "#  'plane_index',\n",
    "#  'check_bag_not_inc_index',\n",
    "#  'dep_weekday_index',\n",
    "#  'dep_time_group_index').dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# from pyspark.ml.linalg import Vectors\n",
    "# from pyspark.ml.feature import VectorAssembler\n",
    "\n",
    "# # from pyspark.ml.feature import VectorAssembler\n",
    "\n",
    "# # ignore = ['id', 'label', 'binomial_label']\n",
    "# # assembler = VectorAssembler(\n",
    "# #     inputCols=[x for x in df.columns if x not in ignore],\n",
    "# #     outputCol='features')\n",
    "\n",
    "# # assembler.transform(df)\n",
    "# # arr_time_group\n",
    "\n",
    "# assembler = VectorAssembler(    \n",
    "#     inputCols=[\n",
    "#  'stay_days',\n",
    "#  'power', \n",
    "#  'span_days',\n",
    "#  'stop',\n",
    "#  'video',\n",
    "#  'wifi',\n",
    "#  'duration_minutes', \n",
    "#  'dep_weeknum',\n",
    "#  'lead_time',\n",
    "#  'trip_index',\n",
    "#  'arr_time_group_index',\n",
    "#  'to_city_name_index',\n",
    "#  'ticket_left_index',\n",
    "#  'company_index',\n",
    "#  'from_city_name_index',\n",
    "#  'airline_code_index',\n",
    "#  'plane_index',\n",
    "#  'check_bag_not_inc_index',\n",
    "#  'dep_weekday_index',\n",
    "#  'dep_time_group_index'],\n",
    "#     outputCol=\"features\")\n",
    "\n",
    "# output = assembler.transform(flight4)\n",
    "# # print(\"Assembled columns 'hour', 'mobile', 'userFeatures' to vector column 'features'\")\n",
    "# # output.select(\"features\", \"clicked\").show(truncate=False)\n",
    "# output = output.withColumnRenamed('price', 'label')\n",
    "# output.show(5, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "display(output.count(), flight6.count(), flight7.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# output.coalesce(2).write.parquet(\"C:\\\\s3\\\\20170503_jsonl\\\\output.parquet\")\n",
    "output.coalesce(2).write.parquet(\"/home/ubuntu/parquet/output.parquet/output.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "output = spark.read.parquet(\"/home/ubuntu/parquet/output.parquet/output.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "output.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "output = output.sample(False, 0.1, seed=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "output.count()\n",
    "output.printSchema()\n",
    "output.show(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# interlude to model in h2o (not sparkling water)  \n",
    "When converting the whole dataset to pandas dataframe, there was not enough RAM, JAVA was forced to shutdown!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "output.printSchema()\n",
    "output2 = output.select('label', 'features')\n",
    "# output2 = output.select('label', 'features').rdd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "output2.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# output2.count()\n",
    "flight_pd = output.select('label', 'price', 'few_tickets_left', \n",
    "                          'from_city_name', 'to_city_name', 'trip', 'stay_days',\n",
    "                          'company', 'flight_code', 'plane', 'span_days', 'stop',\n",
    "                         'power', 'video', 'wifi', 'check_bag_not_inc', \n",
    "                         'dep_time_group', 'arr_time_group',  \n",
    "                         'lead_time', 'dep_weekday', 'dep_weeknum', \n",
    "                         'days_to_last_holiday', 'days_to_next_holiday',                         \n",
    "                         'duration_minutes', 'stop_minutes').toPandas()\n",
    "flight_pd.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# flight_pd.to_csv('C:\\\\s3\\\\20170503_jsonl\\\\flight_pd.csv', sep='\\t')\n",
    "flight_pd.to_csv('/home/ubuntu/parquet/flight_pd.csv', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "h2o.init()\n",
    "# from h2o.estimators.gbm import H2OGradientBoostingEstimator\n",
    "\n",
    "# hf = h2o.H2OFrame(flight_pd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "flight_pd=pd.read_csv(\"/home/ubuntu/parquet/flight_pd.csv\", delimiter='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# flight_pd.head()\n",
    "# help(pd.read_csv)\n",
    "flight_hex = h2o.H2OFrame(flight_pd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train, valid, test = flight_hex.split_frame([0.6, 0.2], seed=1234)\n",
    "\n",
    "flight_X = flight_hex.col_names[2:]\n",
    "flight_y = flight_hex.col_names[1]    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from h2o.estimators.gbm import H2OGradientBoostingEstimator\n",
    "from h2o.estimators.random_forest import H2ORandomForestEstimator\n",
    "\n",
    "rf_v1 = H2ORandomForestEstimator(\n",
    "    model_id=\"rf_v1\",\n",
    "    ntrees=200,\n",
    "    stopping_rounds=2,\n",
    "    score_each_iteration=True,\n",
    "    seed=1000000)\n",
    "\n",
    "rf_v1.train(flight_X, flight_y, training_frame=train, validation_frame=valid)\n",
    "rf_v1\n",
    "rf_v1.score_history()\n",
    "model_path = h2o.save_model(model=rf_v1, path=\"C:\\\\s3\\\\20170503_jsonl\", force=True)\n",
    "print(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rf_v1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# output2.take(2)\n",
    "(trainingData, testData) = output2.randomSplit([0.7, 0.3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stopped here! 20170513"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from time import time\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "\n",
    "# Load training data\n",
    "# training = spark.read.format(\"libsvm\").load(\"data/mllib/sample_libsvm_data.txt\")\n",
    "\n",
    "lr = LogisticRegression(maxIter=100, regParam=0.1, elasticNetParam=0.8)\n",
    "\n",
    "# Fit the model\n",
    "t0 = time()\n",
    "lrModel = lr.fit(trainingData)\n",
    "tt = time() - t0\n",
    "\n",
    "# Print the coefficients and intercept for logistic regression\n",
    "print(\"Classifier trained in \" + str(tt) + \" seconds.\")\n",
    "print(\"Coefficients: \" + str(lrModel.coefficients))\n",
    "print(\"Intercept: \" + str(lrModel.intercept))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import LogisticRegression\n",
    "\n",
    "# Extract the summary from the returned LogisticRegressionModel instance trained\n",
    "# in the earlier example\n",
    "trainingSummary = lrModel.summary\n",
    "\n",
    "# Obtain the objective per iteration\n",
    "objectiveHistory = trainingSummary.objectiveHistory\n",
    "print(\"objectiveHistory:\")\n",
    "for objective in objectiveHistory:\n",
    "    print(objective)\n",
    "\n",
    "# Obtain the receiver-operating characteristic as a dataframe and areaUnderROC.\n",
    "trainingSummary.roc.show()\n",
    "print(\"areaUnderROC: \" + str(trainingSummary.areaUnderROC))\n",
    "\n",
    "# Set the model threshold to maximize F-Measure\n",
    "fMeasure = trainingSummary.fMeasureByThreshold\n",
    "maxFMeasure = fMeasure.groupBy().max('F-Measure').select('max(F-Measure)').head()\n",
    "bestThreshold = fMeasure.where(fMeasure['F-Measure'] == maxFMeasure['max(F-Measure)']) \\\n",
    "    .select('threshold').head()['threshold']\n",
    "lr.setThreshold(bestThreshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Make predictions.\n",
    "predictions = lrModel.transform(testData)\n",
    "\n",
    "# Select example rows to display.\n",
    "predictions.select(\"prediction\", \"label\", \"features\").show(5)\n",
    "predictions.select('label', 'prediction').coalesce(1).write.csv('D://Data Science//pySpark//check_pred7.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.ml import Pipeline\n",
    "# from pyspark.ml.regression import RandomForestRegressor\n",
    "from pyspark.ml.classification import GBTClassifier\n",
    "from pyspark.ml.feature import VectorIndexer\n",
    "# from pyspark.ml.evaluation import RegressionEvaluator\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "\n",
    "# Load and parse the data file, converting it to a DataFrame.\n",
    "# data = spark.read.format(\"libsvm\").load(\"data/mllib/sample_libsvm_data.txt\")\n",
    "\n",
    "# Automatically identify categorical features, and index them.\n",
    "# Set maxCategories so features with > 4 distinct values are treated as continuous.\n",
    "featureIndexer =\\\n",
    "    VectorIndexer(inputCol=\"features\", outputCol=\"indexedFeatures\", maxCategories=100).fit(output)\n",
    "    \n",
    "# Split the data into training and test sets (30% held out for testing)\n",
    "(trainingData, testData) = output.randomSplit([0.7, 0.3])\n",
    "\n",
    "# Train a RandomForest model.\n",
    "# rf = RandomForestRegressor(featuresCol=\"indexedFeatures\", numTrees=1000, featureSubsetStrategy=\"auto\",\n",
    "#                                     impurity='variance', maxDepth=4, maxBins=32)\n",
    "gbt = GBTClassifier(labelCol=\"label\", featuresCol=\"indexedFeatures\", maxIter=10)\n",
    "\n",
    "# Chain indexer and forest in a Pipeline\n",
    "pipeline = Pipeline(stages=[featureIndexer, gbt])\n",
    "\n",
    "# Train model.  This also runs the indexer.\n",
    "model = pipeline.fit(trainingData)\n",
    "\n",
    "# Make predictions.\n",
    "predictions = model.transform(testData)\n",
    "\n",
    "# Select example rows to display.\n",
    "predictions.select(\"prediction\", \"label\", \"features\").show(5)\n",
    "\n",
    "# Select (prediction, true label) and compute test error\n",
    "# evaluator = RegressionEvaluator(\n",
    "#     labelCol=\"label\", predictionCol=\"prediction\", metricName=\"rmse\")\n",
    "evaluator = BinaryClassificationEvaluator(\n",
    "    labelCol=\"label\", predictionCol=\"prediction\")\n",
    "auc = evaluator.evaluate(predictions)\n",
    "print(\"Area under the curve (AUC) on test data = %g\" % auc)\n",
    "\n",
    "gbtModel = model.stages[1]\n",
    "print(gbtModel)  # summary only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import LogisticRegression\n",
    "\n",
    "# Load training data\n",
    "# training = spark.read.format(\"libsvm\").load(\"data/mllib/sample_libsvm_data.txt\")\n",
    "flight7.withColumnRenamed('price_will_drop_num', 'label')\n",
    "\n",
    "lr = LogisticRegression(maxIter=10, regParam=0.3, elasticNetParam=0.8)\n",
    "\n",
    "# Fit the model\n",
    "lrModel = lr.fit(training)\n",
    "\n",
    "# Print the coefficients and intercept for logistic regression\n",
    "print(\"Coefficients: \" + str(lrModel.coefficients))\n",
    "print(\"Intercept: \" + str(lrModel.intercept))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "how to score model manually: http://stackoverflow.com/questions/35731140/apply-model-scores-to-spark-dataframe-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "predictions.select('label', 'prediction').coalesce(1).write.csv('D://Data Science//pySpark//check_pred6.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predictions.show(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.regression import GBTRegressor\n",
    "from pyspark.ml.feature import VectorIndexer\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "\n",
    "# Load and parse the data file, converting it to a DataFrame.\n",
    "data = flight3\n",
    "\n",
    "# Automatically identify categorical features, and index them.\n",
    "# Set maxCategories so features with > 4 distinct values are treated as continuous.\n",
    "# featureIndexer =\\\n",
    "#     VectorIndexer(inputCol=\"features\", outputCol=\"indexedFeatures\", maxCategories=4).fit(data)\n",
    "\n",
    "\n",
    "# Split the data into training and test sets (30% held out for testing)\n",
    "(trainingData, testData) = data.randomSplit([0.7, 0.3])\n",
    "\n",
    "# Train a GBT model.\n",
    "gbt = GBTRegressor(featuresCol=\"indexedFeatures\", maxIter=10)\n",
    "\n",
    "# Chain indexer and GBT in a Pipeline\n",
    "pipeline = Pipeline(stages=[featureIndexer, gbt])\n",
    "\n",
    "# Train model.  This also runs the indexer.\n",
    "model = pipeline.fit(trainingData)\n",
    "\n",
    "# Make predictions.\n",
    "predictions = model.transform(testData)\n",
    "\n",
    "# Select example rows to display.\n",
    "predictions.select(\"prediction\", \"label\", \"features\").show(5)\n",
    "\n",
    "# Select (prediction, true label) and compute test error\n",
    "evaluator = RegressionEvaluator(\n",
    "    labelCol=\"label\", predictionCol=\"prediction\", metricName=\"rmse\")\n",
    "rmse = evaluator.evaluate(predictions)\n",
    "print(\"Root Mean Squared Error (RMSE) on test data = %g\" % rmse)\n",
    "\n",
    "gbtModel = model.stages[1]\n",
    "print(gbtModel)  # summary only\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.regression import GBTRegressor\n",
    "from pyspark.ml.feature import VectorIndexer\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "\n",
    "# # Load and parse the data file, converting it to a DataFrame.\n",
    "# data = spark.read.format(\"libsvm\").load(\"data/mllib/sample_libsvm_data.txt\")\n",
    "\n",
    "# # Automatically identify categorical features, and index them.\n",
    "# # Set maxCategories so features with > 4 distinct values are treated as continuous.\n",
    "featureIndexer =\\\n",
    "    VectorIndexer(inputCol=\"features\", outputCol=\"indexedFeatures\", maxCategories=4).fit(flight3)\n",
    "\n",
    "# # Split the data into training and test sets (30% held out for testing)\n",
    "# (trainingData, testData) = data.randomSplit([0.7, 0.3])\n",
    "\n",
    "# Train a GBT model.\n",
    "gbt = GBTRegressor(featuresCol=\"indexedFeatures\", maxIter=10)\n",
    "\n",
    "# Chain indexer and GBT in a Pipeline\n",
    "pipeline = Pipeline(stages=[featureIndexer, gbt])\n",
    "\n",
    "# Train model.  This also runs the indexer.\n",
    "model = pipeline.fit(trainingData)\n",
    "\n",
    "# Make predictions.\n",
    "predictions = model.transform(testData)\n",
    "\n",
    "# Select example rows to display.\n",
    "predictions.select(\"prediction\", \"label\", \"features\").show(5)\n",
    "\n",
    "# Select (prediction, true label) and compute test error\n",
    "evaluator = RegressionEvaluator(\n",
    "    labelCol=\"label\", predictionCol=\"prediction\", metricName=\"rmse\")\n",
    "rmse = evaluator.evaluate(predictions)\n",
    "print(\"Root Mean Squared Error (RMSE) on test data = %g\" % rmse)\n",
    "\n",
    "gbtModel = model.stages[1]\n",
    "print(gbtModel)  # summary only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# display(flight.select(\"duration\").show())\n",
    "# display(flight2.select(\"duration_h\", 'duration_m').show())\n",
    "display(flight2.show(5))\n",
    "# flight2.toPandas().head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "def getHours(x):\n",
    "  return re.match('([0-9]+(?=h))', x)\n",
    "temp = flight.select(\"duration\").rdd.map(lambda x:getHours(x[0])).toDF()\n",
    "temp.select(\"duration\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "flight.select(\"arr_time\").show(2, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# flight2 = (flight.withColumn('arr_time_local', flight.arr_time.substr(1, 23).cast('date'))                 \n",
    "#           )\n",
    "\n",
    "# flight3 = flight2.withColumn('arr_time', flight2.arr_time.cast('timestamp'))\n",
    "\n",
    "# .select('arr_time').show(2, truncate=False)\n",
    "\n",
    "\n",
    "# flight2 = (flight.withColumn('duration_minutes', flight.duration.substr(1, 23).cast('date'))                 \n",
    "#           )\n",
    "\n",
    "# flight.selectExpr(\"duration\", \"regexp_extract(duration,'([0-9]+(?=h))', 1) as duration_hour\", \"regexp_extract(duration,'([0-9]+(?=m))', 1)\", ).show()\n",
    "flight.selectExpr(\"regexp_extract(duration,'([0-9]+(?=h))', 1) as duration_hour\").duration_hour.cast(\"double\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "flight2.select('arr_time', 'arr_time_local').dtypes\n",
    "flight2.select('arr_time', 'arr_time_local').show(2, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# from pyspark.sql import crosstab\n",
    "# from pyspark.sql.functions import *\n",
    "\n",
    "flight.crosstab('start_date','from_city_name').show()\n",
    "# flight.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "3\n",
    "down vote\n",
    "In order to simply cast a string column to a timestamp, the string column must be properly formatted.\n",
    "\n",
    "To retrieve the \"createdAt\" column as a timestamp, you can write the UDF function that would convert the string\n",
    "\n",
    "\"2016-07-01T16:37:41-0400\"\n",
    "to\n",
    "\n",
    "\"2016-07-01 16:37:41\"\n",
    "and convert the \"createdAt\" column to a new format (don't forget to handle the timezone field).\n",
    "\n",
    "Once you have a column containing timestamps as strings like \"2016-07-01 16:37:41\", a simple cast to timestamp would do the job, as you have it in your code.\n",
    "\n",
    "You can read more about Date/Time/String Handling in Spark here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "display(flight.select(\"arr_time\").take(3))\n",
    "display(flight2.select(\"arr_time\").take(3))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "flight2.withColumn('local', F.from_utc_timestamp(flight2.arr_time, \"AEST\")).select(\"local\").show()\n",
    "flight2.withColumn('local', F.from_utc_timestamp(flight2.arr_time, \"CTZ\")).select(\"local\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import time\n",
    "from datetime import datetime\n",
    "\n",
    "import pytz # $ pip install pytz\n",
    "from tzlocal import get_localzone # $ pip install tzlocal\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# get local timezone    \n",
    "local_tz = get_localzone() \n",
    "print(local_tz)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# test it\n",
    "# utc_now, now = datetime.utcnow(), datetime.now()\n",
    "ts = time.time()\n",
    "utc_now, now = datetime.utcfromtimestamp(ts), datetime.fromtimestamp(ts)\n",
    "print(utc_now)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "local_now = utc_now.replace(tzinfo=pytz.utc).astimezone(local_tz) # utc -> local\n",
    "print(local_now)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "assert local_now.replace(tzinfo=None) == now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# test it\n",
    "# utc_now, now = datetime.utcnow(), datetime.now()\n",
    "ts = time.time()\n",
    "utc_now, now = datetime.utcfromtimestamp(ts), datetime.fromtimestamp(ts)\n",
    "\n",
    "local_now = utc_now.replace(tzinfo=pytz.utc).astimezone(local_tz) # utc -> local\n",
    "assert local_now.replace(tzinfo=None) == now\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Spark-Sql doesn't support date-time, and nor timezones\n",
    "* Using timestamp is the only solution\n",
    "* from_unixtime(at) parses the epoch time correctly, just that the printing of it as a string changes it due to timezone. It is safe to assume that the  from_unixtime will convert it correctly ( although printing it might show different results)\n",
    "* from_utc_timestamp will shift ( not just convert) the timestamp to that timezone, in this case it will subtract 8 hours to the time since (-08:00)\n",
    "* printing sql results messes up the times with respect to timezone param\n",
    "  \t \t\n",
    "* from_unixtime(at) does what from_utc_timestamp does too, it will parse a Unix timestamp integer (seconds since midnight 1970-01-01), and convert the time instant parsed from UTC to the system's default timezone. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "flight2.selectExpr(\"from_utc_timestamp(arr_time, 'AEST') as testthis\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "flight2.dtypes\n",
    "display(flight2.select('arr_time').take(3))\n",
    "display(flight.select('arr_time').take(3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import year, month, dayofmonth, hour, minute, weekofyear, crosstab\n",
    "\n",
    "flight2.select(year(\"arr_time\").alias('year'), \n",
    "               month(\"arr_time\").alias('month'),\n",
    "               dayofmonth(\"arr_time\").alias('day'),\n",
    "               hour(\"arr_time\").alias('hour'),\n",
    "               minute(\"arr_time\").alias('minute'),\n",
    "               weekofyear('arr_time').alias('week_no'),\n",
    "               \"arr_time_zone\"\n",
    "              ).show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import regexp_extract, col\n",
    "\n",
    "#flight.select(regexp_extract('arr_time', r'[+-][0-9]{2}:[0-9]{2}\\b', 1)).alias('d').collect\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = spark.createDataFrame([('2017-04-09T07:15:00.000+08:00',)], ['str'])\n",
    "df.select(regexp_extract('str', '(\\d+)-(\\d+)', 1).alias('d')).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "flight2.describe('price').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import *\n",
    "# flight2.dtypes\n",
    "# flight2.first()\n",
    "display(flight2.select(max(\"start_date\")).show())\n",
    "display(flight2.select(min(\"start_date\")).show())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "flight2 = flight2.withColumn('zero_price', flight2.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# flight.describe().show()\n",
    "flight.describe(\"from_city_name\").show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import colflight.filter(flight.price > 0).groupby(flight.search_date_x, flight.from_city_name, flight.to_city_name).count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col\n",
    "# flight_to_brisbane = flight.where(col(\"price\") > 0 & col(\"to_city_name\") == \"brisbane\").groupby(flight.search_date_x).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.where(col(\"v\").isin({\"foo\", \"bar\"})).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "numeric = sqlContext.createDataFrame([\n",
    "    ('3.5,', '5.0', 'null'), ('2.0', '14.0', 'null'),  ('null', '38.0', 'null'),\n",
    "    ('null', 'null', 'null'),  ('1.0', 'null', '4.0')],\n",
    "    ('low', 'high', 'normal'))\n",
    "\n",
    "numeric_filtered_1 = numeric.where(numeric['LOW'] != 'null')\n",
    "numeric_filtered_1.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "flight.select('from_city_name', 'price').show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "h2o tutorial \n",
    "https://github.com/h2oai/h2o-tutorials/blob/master/tutorials/pysparkling/Chicago_Crime_Demo.md"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
