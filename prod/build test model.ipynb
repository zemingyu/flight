{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - hive</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://172.17.0.2:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v2.2.0</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>PySparkShell</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7fb49ce5efd0>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already up-to-date: colorama in /opt/conda/lib/python3.6/site-packages\n",
      "Connecting to H2O server at http://172.17.0.2:54321... successful.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td>H2O cluster uptime:</td>\n",
       "<td>16 secs</td></tr>\n",
       "<tr><td>H2O cluster version:</td>\n",
       "<td>3.14.0.7</td></tr>\n",
       "<tr><td>H2O cluster version age:</td>\n",
       "<td>1 month </td></tr>\n",
       "<tr><td>H2O cluster name:</td>\n",
       "<td>sparkling-water-jovyan_local-1511264464675</td></tr>\n",
       "<tr><td>H2O cluster total nodes:</td>\n",
       "<td>1</td></tr>\n",
       "<tr><td>H2O cluster free memory:</td>\n",
       "<td>866 Mb</td></tr>\n",
       "<tr><td>H2O cluster total cores:</td>\n",
       "<td>1</td></tr>\n",
       "<tr><td>H2O cluster allowed cores:</td>\n",
       "<td>1</td></tr>\n",
       "<tr><td>H2O cluster status:</td>\n",
       "<td>accepting new members, healthy</td></tr>\n",
       "<tr><td>H2O connection url:</td>\n",
       "<td>http://172.17.0.2:54321</td></tr>\n",
       "<tr><td>H2O connection proxy:</td>\n",
       "<td>None</td></tr>\n",
       "<tr><td>H2O internal security:</td>\n",
       "<td>False</td></tr>\n",
       "<tr><td>H2O API Extensions:</td>\n",
       "<td>XGBoost, Algos, AutoML, Core V3, Core V4</td></tr>\n",
       "<tr><td>Python version:</td>\n",
       "<td>3.6.3 final</td></tr></table></div>"
      ],
      "text/plain": [
       "--------------------------  ------------------------------------------\n",
       "H2O cluster uptime:         16 secs\n",
       "H2O cluster version:        3.14.0.7\n",
       "H2O cluster version age:    1 month\n",
       "H2O cluster name:           sparkling-water-jovyan_local-1511264464675\n",
       "H2O cluster total nodes:    1\n",
       "H2O cluster free memory:    866 Mb\n",
       "H2O cluster total cores:    1\n",
       "H2O cluster allowed cores:  1\n",
       "H2O cluster status:         accepting new members, healthy\n",
       "H2O connection url:         http://172.17.0.2:54321\n",
       "H2O connection proxy:\n",
       "H2O internal security:      False\n",
       "H2O API Extensions:         XGBoost, Algos, AutoML, Core V3, Core V4\n",
       "Python version:             3.6.3 final\n",
       "--------------------------  ------------------------------------------"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sparkling Water Context:\n",
      " * H2O name: sparkling-water-jovyan_local-1511264464675\n",
      " * cluster size: 1\n",
      " * list of used nodes:\n",
      "  (executorId, host, port)\n",
      "  ------------------------\n",
      "  (driver,172.17.0.2,54321)\n",
      "  ------------------------\n",
      "\n",
      "  Open H2O Flow in browser: http://172.17.0.2:54321 (CMD + click in Mac OSX)\n",
      "\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade colorama\n",
    "from pysparkling import *\n",
    "import h2o\n",
    "hc = H2OContext.getOrCreate(spark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as Mnp\n",
    "import pandas.io.sql as psql\n",
    "# import pyodbc\n",
    "import csv\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "### Seaborn style\n",
    "sns.set_style(\"whitegrid\")\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "# pd.set_option('display.float_format', lambda x: '%.3f' % x)\n",
    "pd.set_option('display.float_format', lambda x: '{:,.1f}'.format(x))\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = sqlContext.read.parquet('/home/jovyan/work/sparkling-water-2.2.2/data/s3/flight.pq.11.comb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "106453155"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sample = df.sample(False, 0.000001, 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "96"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sample.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !mkdir /home/jovyan/.local/h2o_jar\n",
    "# !cp /home/jovyan/work/h2o-3.14.0.7/h2o.jar /home/jovyan/.local/h2o_jar\n",
    "# # H2O\n",
    "\n",
    "# # turn off proxy so that h2o can run properly\n",
    "# import os\n",
    "# # os.environ.pop(\"HTTP_PROXY\")\n",
    "\n",
    "# import h2o\n",
    "# h2o.init(nthreads = -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Exception while sending command.\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/spark/python/lib/py4j-0.10.4-src.zip/py4j/java_gateway.py\", line 1035, in send_command\n",
      "    raise Py4JNetworkError(\"Answer from Java side is empty\")\n",
      "py4j.protocol.Py4JNetworkError: Answer from Java side is empty\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/spark/python/lib/py4j-0.10.4-src.zip/py4j/java_gateway.py\", line 883, in send_command\n",
      "    response = connection.send_command(command)\n",
      "  File \"/usr/local/spark/python/lib/py4j-0.10.4-src.zip/py4j/java_gateway.py\", line 1040, in send_command\n",
      "    \"Error while receiving\", e, proto.ERROR_ON_RECEIVE)\n",
      "py4j.protocol.Py4JNetworkError: Error while receiving\n"
     ]
    },
    {
     "ename": "Py4JError",
     "evalue": "An error occurred while calling o43.asH2OFrame",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPy4JError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m/tmp/spark/work/spark-5b81b6b2-1c56-4fba-a883-f3c5a11dc9c2/userFiles-5ff6189c-4079-43e3-8b89-d5fdf1c0bf30/h2o_pysparkling_2.2-2.2.2.zip/pysparkling/context.py\u001b[0m in \u001b[0;36mas_h2o_frame\u001b[0;34m(self, dataframe, framename)\u001b[0m\n\u001b[1;32m    211\u001b[0m         \"\"\"\n\u001b[1;32m    212\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataframe\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDataFrame\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 213\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_as_h2o_frame_from_dataframe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataframe\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mframename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    214\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataframe\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mRDD\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m             \u001b[0;31m# First check if the type T in RDD[T] is one of the python \"primitive\" types\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/spark/work/spark-5b81b6b2-1c56-4fba-a883-f3c5a11dc9c2/userFiles-5ff6189c-4079-43e3-8b89-d5fdf1c0bf30/h2o_pysparkling_2.2-2.2.2.zip/pysparkling/conversions.py\u001b[0m in \u001b[0;36m_as_h2o_frame_from_dataframe\u001b[0;34m(h2oContext, dataframe, frame_name)\u001b[0m\n\u001b[1;32m     42\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdataframe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Cannot transform empty H2OFrame'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m         \u001b[0mj_h2o_frame\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh2oContext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jhc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masH2OFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataframe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mframe_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0mj_h2o_frame_key\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mj_h2o_frame\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mH2OFrame\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_java_h2o_frame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mj_h2o_frame\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mj_h2o_frame_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/spark/python/lib/py4j-0.10.4-src.zip/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1131\u001b[0m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         return_value = get_return_value(\n\u001b[0;32m-> 1133\u001b[0;31m             answer, self.gateway_client, self.target_id, self.name)\n\u001b[0m\u001b[1;32m   1134\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1135\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mtemp_arg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtemp_args\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/spark/python/pyspark/sql/utils.py\u001b[0m in \u001b[0;36mdeco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdeco\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mpy4j\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprotocol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPy4JJavaError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjava_exception\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoString\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/spark/python/lib/py4j-0.10.4-src.zip/py4j/protocol.py\u001b[0m in \u001b[0;36mget_return_value\u001b[0;34m(answer, gateway_client, target_id, name)\u001b[0m\n\u001b[1;32m    325\u001b[0m             raise Py4JError(\n\u001b[1;32m    326\u001b[0m                 \u001b[0;34m\"An error occurred while calling {0}{1}{2}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 327\u001b[0;31m                 format(target_id, \".\", name))\n\u001b[0m\u001b[1;32m    328\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    329\u001b[0m         \u001b[0mtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0manswer\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mPy4JError\u001b[0m: An error occurred while calling o43.asH2OFrame"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "hf = hc.as_h2o_frame(df_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hf.head(5)\n",
    "\n",
    "hf.describe()\n",
    "\n",
    "hf.types\n",
    "\n",
    "hf['leg1_carrierSummary_airlineName'].levels()\n",
    "\n",
    "hf['depDayOfWeek'].levels()\n",
    "\n",
    "# hf['JV_X_Excess'] = hf.interaction(['JV Description', 'Destination'], pairwise=False, max_factors=10, min_occurrence=500)\n",
    "\n",
    "hf.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['price',\n",
    "         'fromCity',\n",
    "         'toCity', \n",
    "         'leadTime',\n",
    "         'leg1_stops',\n",
    "         'leg2_stops',\n",
    "         'leg1_noOfTicketsLeft',\n",
    "         'leg2_noOfTicketsLeft',\n",
    "         'leg1_carrierSummary_airlineName',\n",
    "         'leg2_carrierSummary_airlineName',\n",
    "         'leg1_departureTime_hour',\n",
    "         'leg2_departureTime_hour',\n",
    "         'depWeekOfYear',\n",
    "         'depDayOfWeek',\n",
    "         'retWeekOfYear',\n",
    "         'retDayOfWeek',\n",
    "         'searchDayOfWeek',\n",
    "         'leg1_cabinClass_0',\n",
    "         'leg1_cabinClass_1',\n",
    "         \n",
    "         'leg2_cabinClass_0',\n",
    "         'leg2_cabinClass_1',\n",
    "         \n",
    "         'trip'\n",
    "         ]\n",
    "\n",
    "target = 'priceWillDrop'\n",
    "\n",
    "other_cols = [ 'futureMinPrice', 'saving','searchDate', 'routeCombKey','randVar',\n",
    "             'leg1_cabinClass_2','leg2_cabinClass_2',]\n",
    "\n",
    "features, target\n",
    "\n",
    "hf.describe()\n",
    "\n",
    "hf[hf['leg1_cabinClass_1'].isna(), 'leg1_cabinClass_1'] = 0 #missing\n",
    "hf.describe()\n",
    "\n",
    "hf[target] = hf[target].asfactor()\n",
    "\n",
    "# target = targets[0]\n",
    "# target\n",
    "\n",
    "# hf2 = hf[targets + features2]\n",
    "\n",
    "# # hf2[hf2[target] <= 0, target]=0\n",
    "# for target in targets:\n",
    "#     hf2[hf2[target] > 0, target]=1\n",
    "#     hf2[hf2[target] <= 0, target]=0\n",
    "#     hf2[target] = hf2[target].asfactor()\n",
    "# # for target in targets:\n",
    "# #     hf2[hf2[target] <= 0, target]=0\n",
    "\n",
    "# hf2[hf2['Lead Time'] < 0, 'Lead Time']=0\n",
    "# hf2[hf2['Lead Time'] > 366, 'Lead Time']=366\n",
    "# hf2[hf2['Trip Length'] < 0, 'Trip Length']=0\n",
    "# hf2[hf2['Trip Length'] > 366, 'Trip Length']=366\n",
    "# hf2['excess'] = hf2['excess'].asfactor()\n",
    "# hf2[hf2['oldest age'] < 15, 'oldest age']=15\n",
    "# hf2[hf2['oldest age'] >= 90, 'oldest age']=90\n",
    "# hf2[hf2['Traveller Count'] >= 3, 'Traveller Count']=3\n",
    "\n",
    "df['searchDate'].value_counts()\n",
    "\n",
    "\n",
    "import datetime\n",
    "\n",
    "train=hf[hf['searchDate']<=datetime.datetime(2017, 6, 19, 0, 0, 0), :]\n",
    "valid=hf[(hf['searchDate']>datetime.datetime(2017, 6, 19, 0, 0, 0)) & \n",
    "         (hf['searchDate']<=datetime.datetime(2017, 6, 21, 0, 0, 0)), :]\n",
    "test=hf[hf['searchDate']>datetime.datetime(2017, 6, 21, 0, 0, 0), :]\n",
    "\n",
    "train.shape, test.shape\n",
    "\n",
    "train.nrow, valid.nrow, test.nrow\n",
    "\n",
    "# splits = hf.split_frame(ratios=[0.7, 0.15], seed=1)  \n",
    "\n",
    "# train = splits[0]\n",
    "# valid = splits[1]\n",
    "# test = splits[2]\n",
    "\n",
    "# gbm_regressor.train(x=features, y=targets[0], training_frame=train)\n",
    "\n",
    "# gbm_regressor.model_performance(test)\n",
    "\n",
    "%%time\n",
    "\n",
    "from h2o.estimators.gbm import H2OGradientBoostingEstimator\n",
    "from h2o.automl import H2OAutoML\n",
    "\n",
    "# print(\"############### Modelling: \" + target + \" ################\")\n",
    "gbm = H2OGradientBoostingEstimator(distribution=\"bernoulli\", \n",
    "                                             ntrees=1, max_depth=1, min_rows=1000, learn_rate=1,\n",
    "                                                stopping_rounds=10,\n",
    "                                            stopping_tolerance=0.01, seed=0)\n",
    "gbm.train(x=features, y=target,\n",
    "          training_frame = train,\n",
    "          validation_frame = valid)\n",
    "gbm\n",
    "\n",
    "\n",
    "# Run AutoML for 30 seconds\n",
    "# aml = H2OAutoML(max_runtime_secs = 3600)\n",
    "# aml.train(x=features, y=target,\n",
    "#           training_frame = train,\n",
    "#           validation_frame = valid,\n",
    "#           leaderboard_frame = test)\n",
    "\n",
    "# # View the AutoML Leaderboard\n",
    "# lb = aml.leaderboard\n",
    "# lb\n",
    "# # # aml.leader    \n",
    "\n",
    "aml.leader\n",
    "\n",
    "important_features\n",
    "\n",
    "hf[important_features]\n",
    "\n",
    "%%time\n",
    "\n",
    "imp_threshold = 0.01\n",
    "\n",
    "print(\"############### Modelling: \" + target + \" ################\")\n",
    "model = aml.leader\n",
    "print(model.confusion_matrix(valid=True))    \n",
    "model.varimp_plot()   \n",
    "important_features = [i[0] for i in model.varimp() if i[3]  > imp_threshold]\n",
    "for f in important_features:        \n",
    "    if f in ['price',\n",
    "#              'leg1_carrierSummary_airlineName',\n",
    "             'depWeekOfYear',\n",
    "             'leadTime',\n",
    "#              'leg2_carrierSummary_airlineName',\n",
    "             'depDayOfWeek',\n",
    "             'leg1_departureTime_hour',\n",
    "             'toCity',\n",
    "             'leg2_departureTime_hour',\n",
    "             'searchDayOfWeek',\n",
    "             'leg1_noOfTicketsLeft',\n",
    "             'leg2_noOfTicketsLeft',\n",
    "             'fromCity',\n",
    "             'leg1_stops',\n",
    "             'trip']:\n",
    "#             model.partial_plot(data=valid,cols=[f],server=True, plot=True, nbins=272) \n",
    "#         else:\n",
    "        model.partial_plot(data=test,cols=[f],server=True, plot=True, nbins=21)     #21    \n",
    "model.plot()\n",
    "\n",
    "model.download_mojo(path='D:\\\\flight.pq.11\\\\', get_genmodel_jar=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
