{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - hive</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://172.17.0.2:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v2.2.0</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>PySparkShell</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7f6150827208>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting colorama\n",
      "  Using cached colorama-0.3.9-py2.py3-none-any.whl\n",
      "Installing collected packages: colorama\n",
      "  Found existing installation: colorama 0.3.7\n",
      "    Uninstalling colorama-0.3.7:\n",
      "      Successfully uninstalled colorama-0.3.7\n",
      "Successfully installed colorama-0.3.9\n",
      "[WARNING] H2O requires colorama module of version 0.3.8 or newer. You have version 0.3.7.\n",
      "You can upgrade to the newest version of the module running from the command line\n",
      "    $ pip3 install --upgrade colorama\n",
      "Connecting to H2O server at http://172.17.0.2:54321... successful.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td>H2O cluster uptime:</td>\n",
       "<td>09 secs</td></tr>\n",
       "<tr><td>H2O cluster version:</td>\n",
       "<td>3.14.0.7</td></tr>\n",
       "<tr><td>H2O cluster version age:</td>\n",
       "<td>1 month </td></tr>\n",
       "<tr><td>H2O cluster name:</td>\n",
       "<td>sparkling-water-jovyan_local-1511266040562</td></tr>\n",
       "<tr><td>H2O cluster total nodes:</td>\n",
       "<td>1</td></tr>\n",
       "<tr><td>H2O cluster free memory:</td>\n",
       "<td>2.519 Gb</td></tr>\n",
       "<tr><td>H2O cluster total cores:</td>\n",
       "<td>2</td></tr>\n",
       "<tr><td>H2O cluster allowed cores:</td>\n",
       "<td>2</td></tr>\n",
       "<tr><td>H2O cluster status:</td>\n",
       "<td>accepting new members, healthy</td></tr>\n",
       "<tr><td>H2O connection url:</td>\n",
       "<td>http://172.17.0.2:54321</td></tr>\n",
       "<tr><td>H2O connection proxy:</td>\n",
       "<td>None</td></tr>\n",
       "<tr><td>H2O internal security:</td>\n",
       "<td>False</td></tr>\n",
       "<tr><td>H2O API Extensions:</td>\n",
       "<td>XGBoost, Algos, AutoML, Core V3, Core V4</td></tr>\n",
       "<tr><td>Python version:</td>\n",
       "<td>3.6.3 final</td></tr></table></div>"
      ],
      "text/plain": [
       "--------------------------  ------------------------------------------\n",
       "H2O cluster uptime:         09 secs\n",
       "H2O cluster version:        3.14.0.7\n",
       "H2O cluster version age:    1 month\n",
       "H2O cluster name:           sparkling-water-jovyan_local-1511266040562\n",
       "H2O cluster total nodes:    1\n",
       "H2O cluster free memory:    2.519 Gb\n",
       "H2O cluster total cores:    2\n",
       "H2O cluster allowed cores:  2\n",
       "H2O cluster status:         accepting new members, healthy\n",
       "H2O connection url:         http://172.17.0.2:54321\n",
       "H2O connection proxy:\n",
       "H2O internal security:      False\n",
       "H2O API Extensions:         XGBoost, Algos, AutoML, Core V3, Core V4\n",
       "Python version:             3.6.3 final\n",
       "--------------------------  ------------------------------------------"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sparkling Water Context:\n",
      " * H2O name: sparkling-water-jovyan_local-1511266040562\n",
      " * cluster size: 1\n",
      " * list of used nodes:\n",
      "  (executorId, host, port)\n",
      "  ------------------------\n",
      "  (driver,172.17.0.2,54321)\n",
      "  ------------------------\n",
      "\n",
      "  Open H2O Flow in browser: http://172.17.0.2:54321 (CMD + click in Mac OSX)\n",
      "\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade colorama\n",
    "from pysparkling import *\n",
    "import h2o\n",
    "hc = H2OContext.getOrCreate(spark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pandas.io.sql as psql\n",
    "# import pyodbc\n",
    "import csv\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "### Seaborn style\n",
    "sns.set_style(\"whitegrid\")\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "# pd.set_option('display.float_format', lambda x: '%.3f' % x)\n",
    "pd.set_option('display.float_format', lambda x: '{:,.1f}'.format(x))\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = sqlContext.read.parquet('/home/jovyan/work/sparkling-water-2.2.2/data/s3/flight.pq.11.comb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "106453155"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sample = df.sample(False, 0.000001, 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "96"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sample.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !mkdir /home/jovyan/.local/h2o_jar\n",
    "# !cp /home/jovyan/work/h2o-3.14.0.7/h2o.jar /home/jovyan/.local/h2o_jar\n",
    "# # H2O\n",
    "\n",
    "# # turn off proxy so that h2o can run properly\n",
    "# import os\n",
    "# # os.environ.pop(\"HTTP_PROXY\")\n",
    "\n",
    "# import h2o\n",
    "# h2o.init(nthreads = -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "hf = hc.as_h2o_frame(df_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hf.head(5)\n",
    "\n",
    "hf.describe()\n",
    "\n",
    "hf.types\n",
    "\n",
    "hf['leg1_carrierSummary_airlineName'].levels()\n",
    "\n",
    "hf['depDayOfWeek'].levels()\n",
    "\n",
    "# hf['JV_X_Excess'] = hf.interaction(['JV Description', 'Destination'], pairwise=False, max_factors=10, min_occurrence=500)\n",
    "\n",
    "hf.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['price',\n",
    "         'fromCity',\n",
    "         'toCity', \n",
    "         'leadTime',\n",
    "         'leg1_stops',\n",
    "         'leg2_stops',\n",
    "         'leg1_noOfTicketsLeft',\n",
    "         'leg2_noOfTicketsLeft',\n",
    "         'leg1_carrierSummary_airlineName',\n",
    "         'leg2_carrierSummary_airlineName',\n",
    "         'leg1_departureTime_hour',\n",
    "         'leg2_departureTime_hour',\n",
    "         'depWeekOfYear',\n",
    "         'depDayOfWeek',\n",
    "         'retWeekOfYear',\n",
    "         'retDayOfWeek',\n",
    "         'searchDayOfWeek',\n",
    "         'leg1_cabinClass_0',\n",
    "         'leg1_cabinClass_1',\n",
    "         \n",
    "         'leg2_cabinClass_0',\n",
    "         'leg2_cabinClass_1',\n",
    "         \n",
    "         'trip'\n",
    "         ]\n",
    "\n",
    "target = 'priceWillDrop'\n",
    "\n",
    "other_cols = [ 'futureMinPrice', 'saving','searchDate', 'routeCombKey','randVar',\n",
    "             'leg1_cabinClass_2','leg2_cabinClass_2',]\n",
    "\n",
    "features, target\n",
    "\n",
    "hf.describe()\n",
    "\n",
    "hf[hf['leg1_cabinClass_1'].isna(), 'leg1_cabinClass_1'] = 0 #missing\n",
    "hf.describe()\n",
    "\n",
    "hf[target] = hf[target].asfactor()\n",
    "\n",
    "# target = targets[0]\n",
    "# target\n",
    "\n",
    "# hf2 = hf[targets + features2]\n",
    "\n",
    "# # hf2[hf2[target] <= 0, target]=0\n",
    "# for target in targets:\n",
    "#     hf2[hf2[target] > 0, target]=1\n",
    "#     hf2[hf2[target] <= 0, target]=0\n",
    "#     hf2[target] = hf2[target].asfactor()\n",
    "# # for target in targets:\n",
    "# #     hf2[hf2[target] <= 0, target]=0\n",
    "\n",
    "# hf2[hf2['Lead Time'] < 0, 'Lead Time']=0\n",
    "# hf2[hf2['Lead Time'] > 366, 'Lead Time']=366\n",
    "# hf2[hf2['Trip Length'] < 0, 'Trip Length']=0\n",
    "# hf2[hf2['Trip Length'] > 366, 'Trip Length']=366\n",
    "# hf2['excess'] = hf2['excess'].asfactor()\n",
    "# hf2[hf2['oldest age'] < 15, 'oldest age']=15\n",
    "# hf2[hf2['oldest age'] >= 90, 'oldest age']=90\n",
    "# hf2[hf2['Traveller Count'] >= 3, 'Traveller Count']=3\n",
    "\n",
    "df['searchDate'].value_counts()\n",
    "\n",
    "\n",
    "import datetime\n",
    "\n",
    "train=hf[hf['searchDate']<=datetime.datetime(2017, 6, 19, 0, 0, 0), :]\n",
    "valid=hf[(hf['searchDate']>datetime.datetime(2017, 6, 19, 0, 0, 0)) & \n",
    "         (hf['searchDate']<=datetime.datetime(2017, 6, 21, 0, 0, 0)), :]\n",
    "test=hf[hf['searchDate']>datetime.datetime(2017, 6, 21, 0, 0, 0), :]\n",
    "\n",
    "train.shape, test.shape\n",
    "\n",
    "train.nrow, valid.nrow, test.nrow\n",
    "\n",
    "# splits = hf.split_frame(ratios=[0.7, 0.15], seed=1)  \n",
    "\n",
    "# train = splits[0]\n",
    "# valid = splits[1]\n",
    "# test = splits[2]\n",
    "\n",
    "# gbm_regressor.train(x=features, y=targets[0], training_frame=train)\n",
    "\n",
    "# gbm_regressor.model_performance(test)\n",
    "\n",
    "%%time\n",
    "\n",
    "from h2o.estimators.gbm import H2OGradientBoostingEstimator\n",
    "from h2o.automl import H2OAutoML\n",
    "\n",
    "# print(\"############### Modelling: \" + target + \" ################\")\n",
    "gbm = H2OGradientBoostingEstimator(distribution=\"bernoulli\", \n",
    "                                             ntrees=1, max_depth=1, min_rows=1000, learn_rate=1,\n",
    "                                                stopping_rounds=10,\n",
    "                                            stopping_tolerance=0.01, seed=0)\n",
    "gbm.train(x=features, y=target,\n",
    "          training_frame = train,\n",
    "          validation_frame = valid)\n",
    "gbm\n",
    "\n",
    "\n",
    "# Run AutoML for 30 seconds\n",
    "# aml = H2OAutoML(max_runtime_secs = 3600)\n",
    "# aml.train(x=features, y=target,\n",
    "#           training_frame = train,\n",
    "#           validation_frame = valid,\n",
    "#           leaderboard_frame = test)\n",
    "\n",
    "# # View the AutoML Leaderboard\n",
    "# lb = aml.leaderboard\n",
    "# lb\n",
    "# # # aml.leader    \n",
    "\n",
    "aml.leader\n",
    "\n",
    "important_features\n",
    "\n",
    "hf[important_features]\n",
    "\n",
    "%%time\n",
    "\n",
    "imp_threshold = 0.01\n",
    "\n",
    "print(\"############### Modelling: \" + target + \" ################\")\n",
    "model = aml.leader\n",
    "print(model.confusion_matrix(valid=True))    \n",
    "model.varimp_plot()   \n",
    "important_features = [i[0] for i in model.varimp() if i[3]  > imp_threshold]\n",
    "for f in important_features:        \n",
    "    if f in ['price',\n",
    "#              'leg1_carrierSummary_airlineName',\n",
    "             'depWeekOfYear',\n",
    "             'leadTime',\n",
    "#              'leg2_carrierSummary_airlineName',\n",
    "             'depDayOfWeek',\n",
    "             'leg1_departureTime_hour',\n",
    "             'toCity',\n",
    "             'leg2_departureTime_hour',\n",
    "             'searchDayOfWeek',\n",
    "             'leg1_noOfTicketsLeft',\n",
    "             'leg2_noOfTicketsLeft',\n",
    "             'fromCity',\n",
    "             'leg1_stops',\n",
    "             'trip']:\n",
    "#             model.partial_plot(data=valid,cols=[f],server=True, plot=True, nbins=272) \n",
    "#         else:\n",
    "        model.partial_plot(data=test,cols=[f],server=True, plot=True, nbins=21)     #21    \n",
    "model.plot()\n",
    "\n",
    "model.download_mojo(path='D:\\\\flight.pq.11\\\\', get_genmodel_jar=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
